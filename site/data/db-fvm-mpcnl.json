{
  "name": "db-fvm-mpcnl",
  "namespace": "experiments",
  "description": "Comparison: fsync-per-write (durable) vs no-fsync (volatile page cache) on GKE PD-SSD — measures the true cost of durability across sequential writes, burst writes, batch writes, reads, scans, and mixed OLTP workloads",
  "createdAt": "2026-02-18T17:20:17Z",
  "completedAt": "2026-02-18T18:02:38.108816586Z",
  "durationSeconds": 2541.108816586,
  "phase": "Complete",
  "tags": [
    "comparison",
    "storage",
    "database",
    "baseline"
  ],
  "hypothesis": {
    "claim": "Skipping fsync reduces p99 write latency by 10x+ and increases sustained write throughput by 100x+, while read latency is identical between modes",
    "questions": [
      "What is the true per-write cost of fsync on GKE PD-SSD?",
      "How does write throughput scale when freed from fsync serialization?",
      "Are read and scan operations independent of sync mode?",
      "How does amortized batch-fsync compare to per-write fsync cost?"
    ],
    "focus": [
      "fsync vs page-cache write latency distribution",
      "throughput ceiling with and without durable writes",
      "batch amortization of fsync cost",
      "read path independence from sync mode"
    ]
  },
  "analyzerConfig": {
    "sections": [
      "abstract",
      "capabilitiesMatrix",
      "targetAnalysis",
      "performanceAnalysis",
      "metricInsights",
      "finopsAnalysis",
      "body",
      "feedback",
      "architectureDiagram"
    ]
  },
  "targets": [
    {
      "name": "app",
      "clusterName": "db-fvm-mpcnl-app",
      "clusterType": "gke",
      "machineType": "e2-standard-4",
      "nodeCount": 1,
      "components": [
        "ConfigMap/alloy",
        "ConfigMap/kube-prometheus-stack-alertmanager-overview",
        "ConfigMap/kube-prometheus-stack-apiserver",
        "ConfigMap/kube-prometheus-stack-cluster-total",
        "ConfigMap/kube-prometheus-stack-controller-manager",
        "ConfigMap/kube-prometheus-stack-etcd",
        "ConfigMap/kube-prometheus-stack-grafana",
        "ConfigMap/kube-prometheus-stack-grafana-config-dashboards",
        "ConfigMap/kube-prometheus-stack-grafana-datasource",
        "ConfigMap/kube-prometheus-stack-grafana-overview",
        "ConfigMap/kube-prometheus-stack-k8s-coredns",
        "ConfigMap/kube-prometheus-stack-k8s-resources-cluster",
        "ConfigMap/kube-prometheus-stack-k8s-resources-multicluster",
        "ConfigMap/kube-prometheus-stack-k8s-resources-namespace",
        "ConfigMap/kube-prometheus-stack-k8s-resources-node",
        "ConfigMap/kube-prometheus-stack-k8s-resources-pod",
        "ConfigMap/kube-prometheus-stack-k8s-resources-workload",
        "ConfigMap/kube-prometheus-stack-k8s-resources-workloads-namespace",
        "ConfigMap/kube-prometheus-stack-kubelet",
        "ConfigMap/kube-prometheus-stack-namespace-by-pod",
        "ConfigMap/kube-prometheus-stack-namespace-by-workload",
        "ConfigMap/kube-prometheus-stack-node-cluster-rsrc-use",
        "ConfigMap/kube-prometheus-stack-node-rsrc-use",
        "ConfigMap/kube-prometheus-stack-nodes",
        "ConfigMap/kube-prometheus-stack-nodes-aix",
        "ConfigMap/kube-prometheus-stack-nodes-darwin",
        "ConfigMap/kube-prometheus-stack-persistentvolumesusage",
        "ConfigMap/kube-prometheus-stack-pod-total",
        "ConfigMap/kube-prometheus-stack-prometheus",
        "ConfigMap/kube-prometheus-stack-proxy",
        "ConfigMap/kube-prometheus-stack-scheduler",
        "ConfigMap/kube-prometheus-stack-workload-total",
        "Namespace/observability",
        "Secret/alertmanager-kube-prometheus-stack-alertmanager",
        "Secret/kube-prometheus-stack-grafana",
        "Service/alloy",
        "Service/kube-prometheus-stack-alertmanager",
        "Service/kube-prometheus-stack-grafana",
        "Service/kube-prometheus-stack-kube-state-metrics",
        "Service/kube-prometheus-stack-operator",
        "Service/kube-prometheus-stack-prometheus",
        "Service/kube-prometheus-stack-prometheus-node-exporter",
        "Service/naive-db-fsync",
        "Service/naive-db-nosync",
        "Service/kube-prometheus-stack-coredns",
        "Service/kube-prometheus-stack-kube-controller-manager",
        "Service/kube-prometheus-stack-kube-etcd",
        "Service/kube-prometheus-stack-kube-proxy",
        "Service/kube-prometheus-stack-kube-scheduler",
        "Service/vm-hub",
        "ServiceAccount/alloy",
        "ServiceAccount/kube-prometheus-stack-admission",
        "ServiceAccount/kube-prometheus-stack-alertmanager",
        "ServiceAccount/kube-prometheus-stack-grafana",
        "ServiceAccount/kube-prometheus-stack-kube-state-metrics",
        "ServiceAccount/kube-prometheus-stack-operator",
        "ServiceAccount/kube-prometheus-stack-prometheus",
        "ServiceAccount/kube-prometheus-stack-prometheus-node-exporter",
        "MutatingWebhookConfiguration/kube-prometheus-stack-admission",
        "ValidatingWebhookConfiguration/kube-prometheus-stack-admission",
        "CustomResourceDefinition/alertmanagerconfigs.monitoring.coreos.com",
        "CustomResourceDefinition/alertmanagers.monitoring.coreos.com",
        "CustomResourceDefinition/podlogs.monitoring.grafana.com",
        "CustomResourceDefinition/podmonitors.monitoring.coreos.com",
        "CustomResourceDefinition/probes.monitoring.coreos.com",
        "CustomResourceDefinition/prometheusagents.monitoring.coreos.com",
        "CustomResourceDefinition/prometheuses.monitoring.coreos.com",
        "CustomResourceDefinition/prometheusrules.monitoring.coreos.com",
        "CustomResourceDefinition/scrapeconfigs.monitoring.coreos.com",
        "CustomResourceDefinition/servicemonitors.monitoring.coreos.com",
        "CustomResourceDefinition/thanosrulers.monitoring.coreos.com",
        "DaemonSet/alloy",
        "DaemonSet/kube-prometheus-stack-prometheus-node-exporter",
        "Deployment/kube-prometheus-stack-grafana",
        "Deployment/kube-prometheus-stack-kube-state-metrics",
        "Deployment/kube-prometheus-stack-operator",
        "StatefulSet/naive-db-fsync",
        "StatefulSet/naive-db-nosync",
        "Job/db-benchmark-loadgen",
        "Job/kube-prometheus-stack-admission-create",
        "Alertmanager/kube-prometheus-stack-alertmanager",
        "Prometheus/kube-prometheus-stack-prometheus",
        "PrometheusRule/kube-prometheus-stack-alertmanager.rules",
        "PrometheusRule/kube-prometheus-stack-config-reloaders",
        "PrometheusRule/kube-prometheus-stack-etcd",
        "PrometheusRule/kube-prometheus-stack-general.rules",
        "PrometheusRule/kube-prometheus-stack-k8s.rules.container-cpu-usage-seconds-tot",
        "PrometheusRule/kube-prometheus-stack-k8s.rules.container-memory-cache",
        "PrometheusRule/kube-prometheus-stack-k8s.rules.container-memory-rss",
        "PrometheusRule/kube-prometheus-stack-k8s.rules.container-memory-swap",
        "PrometheusRule/kube-prometheus-stack-k8s.rules.container-memory-working-set-by",
        "PrometheusRule/kube-prometheus-stack-k8s.rules.container-resource",
        "PrometheusRule/kube-prometheus-stack-k8s.rules.pod-owner",
        "PrometheusRule/kube-prometheus-stack-kube-apiserver-availability.rules",
        "PrometheusRule/kube-prometheus-stack-kube-apiserver-burnrate.rules",
        "PrometheusRule/kube-prometheus-stack-kube-apiserver-histogram.rules",
        "PrometheusRule/kube-prometheus-stack-kube-apiserver-slos",
        "PrometheusRule/kube-prometheus-stack-kube-prometheus-general.rules",
        "PrometheusRule/kube-prometheus-stack-kube-prometheus-node-recording.rules",
        "PrometheusRule/kube-prometheus-stack-kube-scheduler.rules",
        "PrometheusRule/kube-prometheus-stack-kube-state-metrics",
        "PrometheusRule/kube-prometheus-stack-kubelet.rules",
        "PrometheusRule/kube-prometheus-stack-kubernetes-apps",
        "PrometheusRule/kube-prometheus-stack-kubernetes-resources",
        "PrometheusRule/kube-prometheus-stack-kubernetes-storage",
        "PrometheusRule/kube-prometheus-stack-kubernetes-system",
        "PrometheusRule/kube-prometheus-stack-kubernetes-system-apiserver",
        "PrometheusRule/kube-prometheus-stack-kubernetes-system-controller-manager",
        "PrometheusRule/kube-prometheus-stack-kubernetes-system-kube-proxy",
        "PrometheusRule/kube-prometheus-stack-kubernetes-system-kubelet",
        "PrometheusRule/kube-prometheus-stack-kubernetes-system-scheduler",
        "PrometheusRule/kube-prometheus-stack-node-exporter",
        "PrometheusRule/kube-prometheus-stack-node-exporter.rules",
        "PrometheusRule/kube-prometheus-stack-node-network",
        "PrometheusRule/kube-prometheus-stack-node.rules",
        "PrometheusRule/kube-prometheus-stack-prometheus",
        "PrometheusRule/kube-prometheus-stack-prometheus-operator",
        "ServiceMonitor/kube-prometheus-stack-alertmanager",
        "ServiceMonitor/kube-prometheus-stack-apiserver",
        "ServiceMonitor/kube-prometheus-stack-coredns",
        "ServiceMonitor/kube-prometheus-stack-grafana",
        "ServiceMonitor/kube-prometheus-stack-kube-controller-manager",
        "ServiceMonitor/kube-prometheus-stack-kube-etcd",
        "ServiceMonitor/kube-prometheus-stack-kube-proxy",
        "ServiceMonitor/kube-prometheus-stack-kube-scheduler",
        "ServiceMonitor/kube-prometheus-stack-kube-state-metrics",
        "ServiceMonitor/kube-prometheus-stack-kubelet",
        "ServiceMonitor/kube-prometheus-stack-operator",
        "ServiceMonitor/kube-prometheus-stack-prometheus",
        "ServiceMonitor/kube-prometheus-stack-prometheus-node-exporter",
        "ServiceMonitor/naive-db-fsync",
        "ServiceMonitor/naive-db-nosync",
        "ClusterRole/alloy",
        "ClusterRole/kube-prometheus-stack-admission",
        "ClusterRole/kube-prometheus-stack-grafana-clusterrole",
        "ClusterRole/kube-prometheus-stack-kube-state-metrics",
        "ClusterRole/kube-prometheus-stack-operator",
        "ClusterRole/kube-prometheus-stack-prometheus",
        "ClusterRoleBinding/alloy",
        "ClusterRoleBinding/kube-prometheus-stack-admission",
        "ClusterRoleBinding/kube-prometheus-stack-grafana-clusterrolebinding",
        "ClusterRoleBinding/kube-prometheus-stack-kube-state-metrics",
        "ClusterRoleBinding/kube-prometheus-stack-operator",
        "ClusterRoleBinding/kube-prometheus-stack-prometheus",
        "Role/kube-prometheus-stack-admission",
        "Role/kube-prometheus-stack-grafana",
        "RoleBinding/kube-prometheus-stack-admission",
        "RoleBinding/kube-prometheus-stack-grafana"
      ]
    }
  ],
  "workflow": {
    "name": "db-fvm-mpcnl-validation",
    "template": "db-fsync-vs-memory-validation",
    "phase": "Succeeded",
    "startedAt": "2026-02-18T17:31:49Z",
    "finishedAt": "2026-02-18T18:02:30Z"
  },
  "metrics": {
    "collectedAt": "2026-02-18T18:03:43.855161979Z",
    "source": "target:db-fvm-mpcnl/kube-prometheus-stack-prometheus",
    "timeRange": {
      "start": "2026-02-18T17:20:17Z",
      "end": "2026-02-18T18:03:43.855137229Z",
      "duration": "43m26.855137229s",
      "stepSeconds": 60
    },
    "queries": {
      "cluster_cpu": {
        "query": "sum(rate(container_cpu_usage_seconds_total{namespace=~\"db-fvm-mpcnl\", container!=\"\"}[1m]))",
        "type": "range",
        "unit": "cores",
        "description": "Total workload CPU usage",
        "data": [
          {
            "timestamp": "2026-02-18T18:03:17Z",
            "value": 0.2878507281159422
          }
        ]
      },
      "cluster_memory": {
        "query": "sum(container_memory_working_set_bytes{namespace=~\"db-fvm-mpcnl\", container!=\"\"})",
        "type": "range",
        "unit": "bytes",
        "description": "Total workload memory usage",
        "data": [
          {
            "timestamp": "2026-02-18T18:03:17Z",
            "value": 582905856
          }
        ]
      },
      "fsync_batch_write_p99": {
        "query": "histogram_quantile(0.99, sum(rate(naivedb_batch_write_duration_seconds_bucket{app=\"naive-db-fsync\", namespace=~\"db-fvm-mpcnl\"}[43m26s])) by (le))",
        "type": "instant",
        "unit": "seconds",
        "description": "Fsync variant: P99 batch write latency"
      },
      "fsync_cpu": {
        "query": "rate(container_cpu_usage_seconds_total{container=\"naive-db-fsync\", namespace=~\"db-fvm-mpcnl\"}[1m])",
        "type": "range",
        "unit": "cores",
        "description": "Fsync variant: CPU usage"
      },
      "fsync_fsync_p99": {
        "query": "histogram_quantile(0.99, sum(rate(naivedb_fsync_duration_seconds_bucket{app=\"naive-db-fsync\", namespace=~\"db-fvm-mpcnl\"}[43m26s])) by (le))",
        "type": "instant",
        "unit": "seconds",
        "description": "Fsync variant: P99 fsync-only latency"
      },
      "fsync_latency_over_time": {
        "query": "histogram_quantile(0.99, sum(rate(naivedb_fsync_duration_seconds_bucket{namespace=~\"db-fvm-mpcnl\"}[1m])) by (le, app))",
        "type": "range",
        "unit": "seconds",
        "description": "P99 fsync latency over time by variant"
      },
      "fsync_memory": {
        "query": "container_memory_working_set_bytes{container=\"naive-db-fsync\", namespace=~\"db-fvm-mpcnl\"}",
        "type": "range",
        "unit": "bytes",
        "description": "Fsync variant: memory usage",
        "data": [
          {
            "labels": {
              "__name__": "container_memory_working_set_bytes",
              "container": "naive-db-fsync",
              "endpoint": "https-metrics",
              "id": "/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod0bcf7871_3bee_4720_b35a_b339debb20cf.slice/cri-containerd-faa3379a05ec92129eb6141ef3305eee327484e674d365b1a7108e0618ede714.scope",
              "image": "ghcr.io/illmadecoder/naive-db:latest",
              "instance": "10.0.0.6:10250",
              "job": "kubelet",
              "metrics_path": "/metrics/cadvisor",
              "name": "faa3379a05ec92129eb6141ef3305eee327484e674d365b1a7108e0618ede714",
              "namespace": "db-fvm-mpcnl",
              "node": "gke-illm-db-fvm-mpcn-db-fvm-mpcnl-app-f1f3ebd6-vp29",
              "pod": "naive-db-fsync-0",
              "service": "kube-prometheus-stack-kubelet"
            },
            "timestamp": "2026-02-18T18:03:17Z",
            "value": 2793472
          }
        ]
      },
      "fsync_read_p99": {
        "query": "histogram_quantile(0.99, sum(rate(naivedb_read_duration_seconds_bucket{app=\"naive-db-fsync\", namespace=~\"db-fvm-mpcnl\"}[43m26s])) by (le))",
        "type": "instant",
        "unit": "seconds",
        "description": "Fsync variant: P99 read latency"
      },
      "fsync_read_throughput": {
        "query": "sum(rate(naivedb_operations_total{op=\"read\", app=\"naive-db-fsync\", namespace=~\"db-fvm-mpcnl\"}[43m26s]))",
        "type": "instant",
        "unit": "ops/s",
        "description": "Fsync variant: read ops/sec"
      },
      "fsync_total_rows": {
        "query": "naivedb_rows_total{app=\"naive-db-fsync\", namespace=~\"db-fvm-mpcnl\"}",
        "type": "instant",
        "unit": "rows",
        "description": "Fsync variant: total rows written",
        "data": [
          {
            "labels": {
              "__name__": "naivedb_rows_total",
              "app": "naive-db-fsync",
              "container": "naive-db-fsync",
              "endpoint": "http",
              "instance": "10.1.0.20:8080",
              "job": "naive-db-fsync",
              "namespace": "db-fvm-mpcnl",
              "pod": "naive-db-fsync-0",
              "service": "naive-db-fsync"
            },
            "timestamp": "2026-02-18T18:03:43Z",
            "value": 13561
          }
        ]
      },
      "fsync_write_p50": {
        "query": "histogram_quantile(0.5, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-fsync\", namespace=~\"db-fvm-mpcnl\"}[43m26s])) by (le))",
        "type": "instant",
        "unit": "seconds",
        "description": "Fsync variant: P50 write latency"
      },
      "fsync_write_p99": {
        "query": "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-fsync\", namespace=~\"db-fvm-mpcnl\"}[43m26s])) by (le))",
        "type": "instant",
        "unit": "seconds",
        "description": "Fsync variant: P99 write latency"
      },
      "fsync_write_throughput": {
        "query": "sum(rate(naivedb_operations_total{op=\"write\", app=\"naive-db-fsync\", namespace=~\"db-fvm-mpcnl\"}[43m26s]))",
        "type": "instant",
        "unit": "ops/s",
        "description": "Fsync variant: write ops/sec"
      },
      "nosync_batch_write_p99": {
        "query": "histogram_quantile(0.99, sum(rate(naivedb_batch_write_duration_seconds_bucket{app=\"naive-db-nosync\", namespace=~\"db-fvm-mpcnl\"}[43m26s])) by (le))",
        "type": "instant",
        "unit": "seconds",
        "description": "NoSync variant: P99 batch write latency"
      },
      "nosync_cpu": {
        "query": "rate(container_cpu_usage_seconds_total{container=\"naive-db-nosync\", namespace=~\"db-fvm-mpcnl\"}[1m])",
        "type": "range",
        "unit": "cores",
        "description": "NoSync variant: CPU usage"
      },
      "nosync_fsync_p99": {
        "query": "histogram_quantile(0.99, sum(rate(naivedb_fsync_duration_seconds_bucket{app=\"naive-db-nosync\", namespace=~\"db-fvm-mpcnl\"}[43m26s])) by (le))",
        "type": "instant",
        "unit": "seconds",
        "description": "NoSync variant: P99 fsync-only latency (should be ~0)"
      },
      "nosync_memory": {
        "query": "container_memory_working_set_bytes{container=\"naive-db-nosync\", namespace=~\"db-fvm-mpcnl\"}",
        "type": "range",
        "unit": "bytes",
        "description": "NoSync variant: memory usage",
        "data": [
          {
            "labels": {
              "__name__": "container_memory_working_set_bytes",
              "container": "naive-db-nosync",
              "endpoint": "https-metrics",
              "id": "/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod4a5a492e_3c22_4c62_8a80_7efa45f7b4bf.slice/cri-containerd-3ff40f00fb0cb11ab48e01b060e293522ffcb84ccb4de56f724080632288969e.scope",
              "image": "ghcr.io/illmadecoder/naive-db:latest",
              "instance": "10.0.0.6:10250",
              "job": "kubelet",
              "metrics_path": "/metrics/cadvisor",
              "name": "3ff40f00fb0cb11ab48e01b060e293522ffcb84ccb4de56f724080632288969e",
              "namespace": "db-fvm-mpcnl",
              "node": "gke-illm-db-fvm-mpcn-db-fvm-mpcnl-app-f1f3ebd6-vp29",
              "pod": "naive-db-nosync-0",
              "service": "kube-prometheus-stack-kubelet"
            },
            "timestamp": "2026-02-18T18:03:17Z",
            "value": 2473984
          }
        ]
      },
      "nosync_read_p99": {
        "query": "histogram_quantile(0.99, sum(rate(naivedb_read_duration_seconds_bucket{app=\"naive-db-nosync\", namespace=~\"db-fvm-mpcnl\"}[43m26s])) by (le))",
        "type": "instant",
        "unit": "seconds",
        "description": "NoSync variant: P99 read latency"
      },
      "nosync_read_throughput": {
        "query": "sum(rate(naivedb_operations_total{op=\"read\", app=\"naive-db-nosync\", namespace=~\"db-fvm-mpcnl\"}[43m26s]))",
        "type": "instant",
        "unit": "ops/s",
        "description": "NoSync variant: read ops/sec"
      },
      "nosync_total_rows": {
        "query": "naivedb_rows_total{app=\"naive-db-nosync\", namespace=~\"db-fvm-mpcnl\"}",
        "type": "instant",
        "unit": "rows",
        "description": "NoSync variant: total rows written",
        "data": [
          {
            "labels": {
              "__name__": "naivedb_rows_total",
              "app": "naive-db-nosync",
              "container": "naive-db-nosync",
              "endpoint": "http",
              "instance": "10.1.0.18:8080",
              "job": "naive-db-nosync",
              "namespace": "db-fvm-mpcnl",
              "pod": "naive-db-nosync-0",
              "service": "naive-db-nosync"
            },
            "timestamp": "2026-02-18T18:03:43Z",
            "value": 13091
          }
        ]
      },
      "nosync_write_p50": {
        "query": "histogram_quantile(0.5, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-nosync\", namespace=~\"db-fvm-mpcnl\"}[43m26s])) by (le))",
        "type": "instant",
        "unit": "seconds",
        "description": "NoSync variant: P50 write latency"
      },
      "nosync_write_p99": {
        "query": "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-nosync\", namespace=~\"db-fvm-mpcnl\"}[43m26s])) by (le))",
        "type": "instant",
        "unit": "seconds",
        "description": "NoSync variant: P99 write latency"
      },
      "nosync_write_throughput": {
        "query": "sum(rate(naivedb_operations_total{op=\"write\", app=\"naive-db-nosync\", namespace=~\"db-fvm-mpcnl\"}[43m26s]))",
        "type": "instant",
        "unit": "ops/s",
        "description": "NoSync variant: write ops/sec"
      },
      "read_throughput_over_time": {
        "query": "sum(rate(naivedb_operations_total{op=\"read\", namespace=~\"db-fvm-mpcnl\"}[1m])) by (app)",
        "type": "range",
        "unit": "ops/s",
        "description": "Read throughput over time by variant"
      },
      "write_latency_over_time": {
        "query": "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{namespace=~\"db-fvm-mpcnl\"}[1m])) by (le, app))",
        "type": "range",
        "unit": "seconds",
        "description": "P99 write latency over time by variant"
      },
      "write_throughput_over_time": {
        "query": "sum(rate(naivedb_operations_total{op=\"write\", namespace=~\"db-fvm-mpcnl\"}[1m])) by (app)",
        "type": "range",
        "unit": "ops/s",
        "description": "Write throughput over time by variant"
      }
    }
  },
  "costEstimate": {
    "totalUSD": 0.018917143412362447,
    "durationHours": 0.7058635601627777,
    "perTarget": {
      "app": 0.018917143412362447
    },
    "note": "Rough estimate based on on-demand GCE pricing; actual cost may differ."
  },
  "analysis": {
    "finopsAnalysis": {
      "overview": "This experiment ran a single e2-standard-4 GKE node for ~42 minutes at an estimated cost of $0.019. The workload was extremely lightweight — 0.29 vCPUs and ~556 MiB memory consumed — meaning the node was heavily underutilized (7% CPU, 3.5% memory of the 4-vCPU/16-GiB e2-standard-4). The observability stack (Prometheus, Grafana, Alertmanager, Alloy, kube-state-metrics, node-exporter) likely consumed more resources than the two naive-db StatefulSets under test.",
      "costDrivers": [
        "GKE node compute: The e2-standard-4 instance ($0.134/hr on-demand) is the sole cost driver at $0.019 for ~42 minutes. The two naive-db containers used ~5 MiB combined memory and negligible CPU — the node is 90%+ idle, with overhead dominated by the monitoring stack.",
        "PD-SSD persistent volumes: StatefulSets for naive-db-fsync and naive-db-nosync each mount PD-SSD volumes. With only ~13K rows written per variant, storage I/O costs are negligible (<$0.001), but PD-SSD provisioned capacity charges ($0.17/GB/month) apply regardless of utilization."
      ],
      "projection": "Production projection for 24/7 operation on non-preemptible nodes: A realistic production setup would run 3 nodes (HA) with e2-standard-4 instances plus PD-SSD storage. Math: e2-standard-4 on-demand = $0.134/hr × 3 nodes × 730 hrs/month = $293.46/month compute. PD-SSD storage (assume 100 GB per node for DB + WAL) = 300 GB × $0.17/GB/month = $51.00/month. Prometheus/Grafana stack persistent storage (50 GB) = $8.50/month. GKE cluster management fee = $0.00 (free tier for one zonal cluster, $73/month for Autopilot or Standard with management fee). Network egress (monitoring telemetry, inter-node) ≈ $5–10/month. Total estimated monthly cost: ~$355–$365/month for a 3-node production cluster. If using n2-standard-4 for better storage I/O performance (relevant for fsync-heavy workloads), compute rises to $0.194/hr × 3 × 730 = $424.86, pushing total to ~$485/month.",
      "optimizations": [
        "Right-size the experiment node: The workload used 0.29 vCPUs and 556 MiB. An e2-medium (1 vCPU, 4 GiB) at $0.034/hr would suffice for benchmarking, saving ~75% on compute ($0.005 vs $0.019 per run).",
        "Use preemptible/spot VMs for experiments: Spot e2-standard-4 instances cost ~$0.040/hr (70% savings). For non-production benchmarks with ~42-minute runtime, preemption risk is minimal. Saves ~$0.013 per run.",
        "Reduce observability footprint for experiments: The full kube-prometheus-stack (Grafana, Alertmanager, 30+ ConfigMaps for dashboards) is heavy for a single-node benchmark. A minimal Prometheus + node-exporter setup would free ~200-300 MiB RAM and allow a smaller node.",
        "Separate monitoring from workload nodes in production: In the current setup, Prometheus and the DB compete for the same PD-SSD I/O budget. Production deployments should isolate monitoring onto dedicated nodes or use a managed service (Google Cloud Managed Prometheus) to avoid I/O contention that could skew fsync latency measurements."
      ]
    },
    "capabilitiesMatrix": {
      "technologies": [
        "naive-db-fsync",
        "naive-db-nosync"
      ],
      "categories": [
        {
          "name": "Write Latency",
          "capabilities": [
            {
              "name": "P50 write latency",
              "values": {
                "naive-db-fsync": "No data returned (query empty — likely in fsync-dominated ms range)",
                "naive-db-nosync": "No data returned (query empty — likely sub-ms page-cache writes)"
              }
            },
            {
              "name": "P99 write latency",
              "values": {
                "naive-db-fsync": "No data returned (expected 1–5ms per PD-SSD fsync round-trip)",
                "naive-db-nosync": "No data returned (expected <0.1ms page-cache only)"
              }
            },
            {
              "name": "P99 fsync-only latency",
              "values": {
                "naive-db-fsync": "No data returned (expected 0.5–2ms per fsync on GKE PD-SSD)",
                "naive-db-nosync": "Expected ~0 (no fsync calls issued)"
              }
            }
          ]
        },
        {
          "name": "Write Throughput",
          "capabilities": [
            {
              "name": "Sustained write ops/sec",
              "values": {
                "naive-db-fsync": "No data returned (expected ~500–1000 ops/s, serialized by fsync)",
                "naive-db-nosync": "No data returned (expected 10,000+ ops/s, CPU/memory bound)"
              }
            },
            {
              "name": "Total rows written",
              "values": {
                "naive-db-fsync": "13,561 rows over ~30min benchmark window",
                "naive-db-nosync": "13,091 rows over ~30min benchmark window"
              }
            },
            {
              "name": "Batch write P99 latency",
              "values": {
                "naive-db-fsync": "No data returned (batch-fsync amortization unmeasured)",
                "naive-db-nosync": "No data returned"
              }
            }
          ]
        },
        {
          "name": "Read Performance",
          "capabilities": [
            {
              "name": "P99 read latency",
              "values": {
                "naive-db-fsync": "No data returned",
                "naive-db-nosync": "No data returned"
              }
            },
            {
              "name": "Read throughput (ops/sec)",
              "values": {
                "naive-db-fsync": "No data returned",
                "naive-db-nosync": "No data returned"
              }
            }
          ]
        },
        {
          "name": "Resource Efficiency",
          "capabilities": [
            {
              "name": "Memory working set",
              "values": {
                "naive-db-fsync": "~2.8 MB (minimal footprint)",
                "naive-db-nosync": "~2.5 MB (minimal footprint)"
              }
            },
            {
              "name": "CPU usage",
              "values": {
                "naive-db-fsync": "No time-series data returned (range query empty)",
                "naive-db-nosync": "No time-series data returned (range query empty)"
              }
            },
            {
              "name": "Total cluster overhead",
              "values": {
                "naive-db-fsync": "~0.29 cores / ~556 MB cluster-wide (shared observability stack)",
                "naive-db-nosync": "Same cluster — shared overhead"
              }
            }
          ]
        },
        {
          "name": "Durability & Data Safety",
          "capabilities": [
            {
              "name": "Crash durability guarantee",
              "values": {
                "naive-db-fsync": "Full — every write persisted to PD-SSD before ack",
                "naive-db-nosync": "None — up to ~30s of writes lost on crash (kernel dirty writeback window)"
              }
            },
            {
              "name": "Suitability for transactional workloads",
              "values": {
                "naive-db-fsync": "Required for ACID-like guarantees",
                "naive-db-nosync": "Acceptable only for ephemeral/rebuildable data"
              }
            }
          ]
        }
      ],
      "summary": "This experiment is largely inconclusive: the vast majority of instant Prometheus queries returned no data, meaning the core latency and throughput histograms were either not scraped, not emitted during the benchmark window, or the query time range did not align with metric availability. The only concrete data points — total rows written — show nearly identical counts (~13.5k fsync vs ~13.1k nosync), which contradicts the hypothesis that nosync should achieve 100x+ higher throughput and strongly suggests the load generator was not driving enough concurrent pressure to saturate either mode. The experiment must be re-run with verified metric emission and a higher-pressure workload before any meaningful fsync-vs-nosync verdict can be drawn."
    },
    "feedback": {
      "recommendations": [
        "Verify histogram metric emission before running the full benchmark: add a pre-flight check that confirms naivedb_write_duration_seconds_bucket, naivedb_read_duration_seconds_bucket, naivedb_fsync_duration_seconds_bucket, and naivedb_batch_write_duration_seconds_bucket are all being scraped and contain non-zero observations in Prometheus before the load generator starts its timed phases.",
        "Increase load generator concurrency and duration significantly — the nearly identical row counts (~13.5k vs ~13.1k) suggest the workload was request-rate-limited rather than backend-limited, masking the fsync serialization bottleneck entirely. Target at least 10x more writes with concurrent clients to surface the throughput divergence.",
        "Use shorter Prometheus rate() windows for instant queries (e.g., 5m instead of the full 43m experiment window) or collect the histograms as client-side summaries in the load generator itself, to avoid diluting burst-phase metrics across idle periods.",
        "Add an explicit crash-recovery test phase: kill the pod mid-write and verify row counts on restart, to empirically demonstrate the durability gap rather than only measuring performance."
      ],
      "experimentDesign": [
        "Separate the benchmark into distinct, non-overlapping phases (sequential writes, burst writes, batch writes, reads, scans, mixed) with phase markers emitted as Prometheus annotations or metric labels, so each phase can be queried independently rather than aggregated over the full experiment duration.",
        "Add client-side latency recording in the load generator job (e.g., HDR histogram exported as a ConfigMap or log artifact) as a second source of truth that does not depend on Prometheus scrape alignment — this would have caught the missing-data problem immediately.",
        "Run the fsync and nosync variants on separate nodes (or at minimum, separate PVCs on isolated PD-SSD volumes) to eliminate any possibility of I/O contention or page-cache interference between the two workloads sharing the same node."
      ]
    },
    "body": {
      "blocks": [
        {
          "type": "text",
          "content": "This experiment compared naive-db with fsync-per-write (durable) against no-fsync (page-cache only) on GKE PD-SSD. The results are **largely inconclusive**: most Prometheus histogram queries returned no data, and the two variants wrote nearly identical row counts — strongly suggesting the load generator was request-rate-limited rather than backend-limited."
        },
        {
          "type": "callout",
          "variant": "warning",
          "title": "Experiment Inconclusive — Missing Metric Data",
          "content": "The majority of latency and throughput histogram queries returned empty results. Only total row counts, memory usage, and cluster-level resource metrics contain data. The core hypothesis (10x latency reduction, 100x throughput gain) cannot be validated or rejected from this run."
        },
        {
          "type": "topic",
          "title": "Write Performance: The Missing Signal",
          "blocks": [
            {
              "type": "text",
              "content": "The experiment's central question — how much does fsync cost per write on PD-SSD — remains unanswered. All write latency histograms (P50, P99) and throughput counters returned empty, indicating the metrics were either not emitted or not aligned with the Prometheus scrape window."
            },
            {
              "type": "row",
              "blocks": [
                {
                  "type": "metric",
                  "key": "fsync_total_rows",
                  "size": "small",
                  "insight": "13,561 rows — far below what a 30-minute benchmark should produce if fsync is the bottleneck"
                },
                {
                  "type": "metric",
                  "key": "nosync_total_rows",
                  "size": "small",
                  "insight": "13,091 rows — nearly identical to fsync, suggesting the load generator was the bottleneck, not disk I/O"
                }
              ]
            },
            {
              "type": "comparison",
              "items": [
                {
                  "label": "Expected Throughput Gap",
                  "value": "100x+",
                  "description": "Hypothesis predicted nosync would achieve 100x+ higher write throughput than fsync"
                },
                {
                  "label": "Observed Throughput Gap",
                  "value": "~1.04x",
                  "description": "Fsync actually wrote 3.6% more rows — within noise, indicating the load generator was rate-limited"
                }
              ]
            },
            {
              "type": "metric",
              "key": "write_throughput_over_time",
              "size": "large",
              "insight": "Time-series write throughput should reveal burst phases, but data gaps make this unreliable"
            },
            {
              "type": "metric",
              "key": "write_latency_over_time",
              "size": "large",
              "insight": "P99 write latency over time — expected to show clear separation between fsync and nosync variants"
            }
          ]
        },
        {
          "type": "topic",
          "title": "Fsync Latency & Batch Amortization",
          "blocks": [
            {
              "type": "text",
              "content": "The fsync-specific latency histogram and batch write metrics both returned empty. On GKE PD-SSD, per-write fsync typically costs 0.5–2ms, meaning a properly loaded benchmark should show ~500–1000 serialized writes/sec for fsync vs 10,000+ for nosync."
            },
            {
              "type": "metric",
              "key": "fsync_latency_over_time",
              "size": "large",
              "insight": "Fsync latency time-series — critical for understanding PD-SSD round-trip cost"
            },
            {
              "type": "row",
              "blocks": [
                {
                  "type": "metric",
                  "key": "fsync_batch_write_p99",
                  "size": "small",
                  "insight": "No data — batch-fsync amortization cost is unknown"
                },
                {
                  "type": "metric",
                  "key": "nosync_batch_write_p99",
                  "size": "small",
                  "insight": "No data — cannot compare batch write behavior between modes"
                }
              ]
            },
            {
              "type": "callout",
              "variant": "finding",
              "title": "Batch Amortization Unmeasured",
              "content": "A key question — whether batching N writes into a single fsync reduces per-write cost to 1/N — has no data to analyze. The batch_write_duration histogram appears to have zero observations in both variants."
            }
          ]
        },
        {
          "type": "topic",
          "title": "Read Performance & Mode Independence",
          "blocks": [
            {
              "type": "text",
              "content": "The hypothesis that read latency is identical between fsync and nosync modes could not be validated. All read latency and throughput queries returned empty results."
            },
            {
              "type": "metric",
              "key": "read_throughput_over_time",
              "size": "large",
              "insight": "Read throughput over time — should show identical curves if reads are sync-mode-independent"
            },
            {
              "type": "row",
              "blocks": [
                {
                  "type": "metric",
                  "key": "fsync_read_p99",
                  "size": "small",
                  "insight": "No data returned"
                },
                {
                  "type": "metric",
                  "key": "nosync_read_p99",
                  "size": "small",
                  "insight": "No data returned"
                }
              ]
            },
            {
              "type": "text",
              "content": "Since reads in both modes go through the Linux page cache (data is always cached after write), there is no theoretical reason for read performance to differ. A properly instrumented re-run should confirm this."
            }
          ]
        },
        {
          "type": "topic",
          "title": "Resource Efficiency & Cost",
          "blocks": [
            {
              "type": "text",
              "content": "Both naive-db variants consumed minimal resources. The e2-standard-4 node was heavily underutilized at 7% CPU and 3.5% memory, with the observability stack consuming the vast majority of cluster resources."
            },
            {
              "type": "row",
              "blocks": [
                {
                  "type": "metric",
                  "key": "cluster_cpu",
                  "size": "small",
                  "insight": "0.29 cores total — 93% of the 4-vCPU node sits idle"
                },
                {
                  "type": "metric",
                  "key": "cluster_memory",
                  "size": "small",
                  "insight": "~556 MiB total — dominated by the monitoring stack, not the DB workload"
                }
              ]
            },
            {
              "type": "row",
              "blocks": [
                {
                  "type": "metric",
                  "key": "fsync_memory",
                  "size": "small",
                  "insight": "~2.8 MB — the fsync variant uses negligible memory"
                },
                {
                  "type": "metric",
                  "key": "nosync_memory",
                  "size": "small",
                  "insight": "~2.5 MB — virtually identical to fsync; sync mode has no memory impact"
                }
              ]
            },
            {
              "type": "comparison",
              "items": [
                {
                  "label": "Experiment Cost",
                  "value": "$0.019",
                  "description": "42-minute run on a single e2-standard-4 node"
                },
                {
                  "label": "Right-Sized Cost",
                  "value": "~$0.005",
                  "description": "An e2-medium (1 vCPU, 4 GiB) would suffice, saving 75%"
                },
                {
                  "label": "Production Estimate",
                  "value": "~$360/mo",
                  "description": "3-node HA cluster with PD-SSD and monitoring"
                }
              ]
            },
            {
              "type": "table",
              "headers": [
                "Component",
                "CPU (cores)",
                "Memory",
                "% of Cluster"
              ],
              "rows": [
                [
                  "naive-db-fsync",
                  "~0",
                  "2.8 MB",
                  "<1%"
                ],
                [
                  "naive-db-nosync",
                  "~0",
                  "2.5 MB",
                  "<1%"
                ],
                [
                  "Observability Stack",
                  "~0.28",
                  "~550 MB",
                  "~99%"
                ],
                [
                  "Total Cluster",
                  "0.29",
                  "556 MB",
                  "100%"
                ]
              ],
              "caption": "The monitoring stack dominates resource usage — the actual DB workload is negligible"
            }
          ]
        },
        {
          "type": "topic",
          "title": "Durability Trade-offs",
          "blocks": [
            {
              "type": "text",
              "content": "While performance data is missing, the durability guarantees between modes are architecturally clear and represent the fundamental trade-off this experiment aims to quantify."
            },
            {
              "type": "capabilityRow",
              "capability": "Crash durability guarantee",
              "values": {
                "naive-db-fsync": "Full — every write persisted to PD-SSD before acknowledgment",
                "naive-db-nosync": "None — up to 30s of writes lost on crash (kernel dirty writeback window)"
              }
            },
            {
              "type": "capabilityRow",
              "capability": "Transactional workload suitability",
              "values": {
                "naive-db-fsync": "Required for ACID-like guarantees",
                "naive-db-nosync": "Only for ephemeral or rebuildable data"
              }
            },
            {
              "type": "capabilityRow",
              "capability": "Expected write throughput ceiling",
              "values": {
                "naive-db-fsync": "~500–1,000 ops/s (serialized by PD-SSD round-trip)",
                "naive-db-nosync": "10,000+ ops/s (CPU/memory bound only)"
              }
            },
            {
              "type": "callout",
              "variant": "info",
              "title": "The Missing Crash Test",
              "content": "This experiment measured only performance, not actual durability. A crash-recovery phase — killing the pod mid-write and verifying row counts on restart — would empirically demonstrate the data loss gap between modes."
            }
          ]
        },
        {
          "type": "text",
          "content": "**Verdict: Re-run required.** The nearly identical row counts (~13.5K vs ~13.1K) and empty histogram data make this experiment unsuitable for drawing conclusions about fsync cost on GKE PD-SSD. The following recommendations address the root causes."
        },
        {
          "type": "recommendation",
          "priority": "p0",
          "title": "Verify metric emission before starting the benchmark",
          "description": "Add a pre-flight check confirming that naivedb_write_duration_seconds_bucket, naivedb_read_duration_seconds_bucket, naivedb_fsync_duration_seconds_bucket, and naivedb_batch_write_duration_seconds_bucket are all being scraped with non-zero observations before the load generator begins timed phases.",
          "effort": "low"
        },
        {
          "type": "recommendation",
          "priority": "p0",
          "title": "Increase load generator concurrency to saturate both modes",
          "description": "The identical row counts prove the load generator was the bottleneck, not the storage backend. Use multiple concurrent writers to drive throughput high enough that fsync serialization becomes visible. Target at least 10x more total writes.",
          "effort": "medium"
        },
        {
          "type": "recommendation",
          "priority": "p1",
          "title": "Add client-side latency recording as a second source of truth",
          "description": "Record HDR histograms in the load generator itself (exported as a ConfigMap or log artifact) so latency data does not depend on Prometheus scrape alignment. This would have immediately revealed the missing-data problem.",
          "effort": "medium"
        },
        {
          "type": "recommendation",
          "priority": "p1",
          "title": "Isolate variants on separate PD-SSD volumes",
          "description": "Run fsync and nosync on separate nodes or at minimum separate PVCs to eliminate I/O contention and page-cache interference between the two workloads sharing the same disk.",
          "effort": "medium"
        },
        {
          "type": "recommendation",
          "priority": "p2",
          "title": "Right-size the experiment node to e2-medium",
          "description": "The workload used 0.29 vCPUs and 556 MiB. An e2-medium (1 vCPU, 4 GiB) at $0.034/hr would suffice, saving ~75% on per-run compute cost.",
          "effort": "low"
        },
        {
          "type": "recommendation",
          "priority": "p2",
          "title": "Add an explicit crash-recovery test phase",
          "description": "Kill the pod mid-write and verify row counts on restart to empirically demonstrate the durability gap between fsync and nosync modes, rather than relying solely on performance measurements.",
          "effort": "medium"
        }
      ]
    },
    "summary": "Analysis incomplete",
    "generatedAt": "2026-02-18T18:10:49Z",
    "model": "claude-opus-4-6"
  }
}
