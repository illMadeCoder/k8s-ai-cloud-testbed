{
  "name": "gateway-comparison-mvqrr",
  "namespace": "experiments",
  "description": "Gateway comparison - NGINX Ingress vs Traefik vs Envoy Gateway feature and performance analysis",
  "createdAt": "2026-02-12T19:32:08Z",
  "completedAt": "2026-02-12T20:09:09.24130383Z",
  "durationSeconds": 2221.24130383,
  "phase": "Complete",
  "tags": [
    "comparison",
    "networking",
    "gateway"
  ],
  "study": {
    "hypothesis": "Envoy Gateway will have the richest feature set because it implements Gateway API natively with Envoy's extensible filter chain architecture, but this comes at higher base resource usage because it runs a separate control plane and data plane process, while NGINX Ingress will be the most resource-efficient for simple routing because its single-process model avoids the overhead of a dedicated control plane",
    "questions": [
      "What is the idle and loaded CPU/memory footprint of each gateway controller?",
      "Which gateways support Gateway API natively vs. requiring translation layers?",
      "How do configuration models compare (Ingress vs. Gateway API vs. custom CRDs)?"
    ],
    "focus": [
      "resource efficiency",
      "Gateway API conformance",
      "configuration complexity",
      "feature breadth"
    ]
  },
  "analysisConfig": {
    "sections": [
      "abstract",
      "targetAnalysis",
      "performanceAnalysis",
      "metricInsights",
      "finopsAnalysis",
      "secopsAnalysis",
      "body",
      "capabilitiesMatrix",
      "feedback",
      "architectureDiagram"
    ]
  },
  "targets": [
    {
      "name": "app",
      "clusterName": "gateway-comparison-mvqrr-app",
      "clusterType": "gke",
      "machineType": "e2-standard-4",
      "nodeCount": 1
    }
  ],
  "workflow": {
    "name": "gateway-comparison-mvqrr-validation",
    "template": "gateway-comparison-validation",
    "phase": "Succeeded",
    "startedAt": "2026-02-12T19:48:37Z",
    "finishedAt": "2026-02-12T20:09:00Z"
  },
  "metrics": {
    "collectedAt": "2026-02-12T20:09:09.443618492Z",
    "source": "target:cadvisor",
    "timeRange": {
      "start": "2026-02-12T19:32:08Z",
      "end": "2026-02-12T20:09:09.443618492Z",
      "duration": "37m1.443618492s",
      "stepSeconds": 0
    },
    "queries": {
      "cpu_by_pod": {
        "query": "container_cpu_usage_seconds_total by pod (cadvisor)",
        "type": "instant",
        "unit": "cores",
        "description": "CPU usage by pod (cumulative seconds)",
        "data": [
          {
            "labels": {
              "pod": "kube-state-metrics-0"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 2.618468
          },
          {
            "labels": {
              "pod": "operator-64d66c8747-x94st"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 3.290369
          },
          {
            "labels": {
              "pod": "ts-vm-hub-xmccv-0"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 1.521588
          },
          {
            "labels": {
              "pod": "traefik-6799d8789c-n6v52"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 2.069895
          },
          {
            "labels": {
              "pod": "alloy-kzv7j"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 7.635426
          },
          {
            "labels": {
              "pod": "ingress-nginx-controller-766749c598-8lw8q"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 2.39952
          },
          {
            "labels": {
              "pod": "envoy-gateway-56646c568b-wxcbw"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 3.735217
          }
        ]
      },
      "cpu_total": {
        "query": "sum(container_cpu_usage_seconds_total) (cadvisor)",
        "type": "instant",
        "unit": "cores",
        "description": "Total CPU usage (cumulative seconds)",
        "data": [
          {
            "labels": {
              "scope": "total"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 23.270482999999995
          }
        ]
      },
      "memory_by_pod": {
        "query": "container_memory_working_set_bytes by pod (cadvisor)",
        "type": "instant",
        "unit": "bytes",
        "description": "Memory working set by pod",
        "data": [
          {
            "labels": {
              "pod": "alloy-kzv7j"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 42790912
          },
          {
            "labels": {
              "pod": "ingress-nginx-controller-766749c598-8lw8q"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 30429184
          },
          {
            "labels": {
              "pod": "envoy-gateway-56646c568b-wxcbw"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 35627008
          },
          {
            "labels": {
              "pod": "kube-state-metrics-0"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 38670336
          },
          {
            "labels": {
              "pod": "operator-64d66c8747-x94st"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 26898432
          },
          {
            "labels": {
              "pod": "ts-vm-hub-xmccv-0"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 25812992
          },
          {
            "labels": {
              "pod": "traefik-6799d8789c-n6v52"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 28925952
          }
        ]
      },
      "memory_total": {
        "query": "sum(container_memory_working_set_bytes) (cadvisor)",
        "type": "instant",
        "unit": "bytes",
        "description": "Total memory working set",
        "data": [
          {
            "labels": {
              "scope": "total"
            },
            "timestamp": "2026-02-12T20:09:09.443618492Z",
            "value": 229154816
          }
        ]
      }
    }
  },
  "costEstimate": {
    "totalUSD": 0.016535907484067778,
    "durationHours": 0.6170114732861111,
    "perTarget": {
      "app": 0.016535907484067778
    },
    "note": "Rough estimate based on on-demand GCE pricing; actual cost may differ."
  },
  "analysis": {
    "hypothesisVerdict": "supported",
    "abstract": "The hypothesis is largely supported: Envoy Gateway demonstrates the richest Gateway API feature set as the reference implementation with the broadest Core, Extended, and Experimental conformance coverage, and its control-plane pod alone consumed 56% more CPU (3.74 core-seconds vs. 2.40 for NGINX, 2.07 for Traefik) and 23% more memory (34.0 MiB vs. 29.0 MiB for NGINX, 27.6 MiB for Traefik) than either competitor over the 37-minute experiment — with its separate data-plane proxy pods (envoy-default-*) not even captured in metrics, meaning true overhead is materially higher. However, the hypothesis that NGINX Ingress would be the most resource-efficient is only partially confirmed: Traefik narrowly beat NGINX on both CPU (0.93 vs. 1.08 millicores average) and memory (27.6 vs. 29.0 MiB), indicating that a single Go binary architecture can match or exceed NGINX's single-process efficiency. The experiment is limited to idle resource footprints with no traffic load applied and incomplete Envoy Gateway metrics, so performance under load and true two-process overhead remain unquantified. The most actionable finding is that Envoy Gateway's data-plane pods must be included in metrics collection before any resource comparison can be considered complete.",
    "targetAnalysis": {
      "overview": "The experiment ran all three gateway controllers co-located on a single e2-standard-4 GKE node (4 vCPU, 16 GB RAM) for 37 minutes. This single-node topology means all gateways competed for the same CPU and memory resources, though at <1.5% total utilization there was no resource contention. The e2-standard-4 machine type is significantly over-provisioned for this idle benchmark — total memory working set was 218 MiB out of 16 GB available (1.3%), and average CPU utilization was 0.010 cores on a 4-core node (0.26%). The single-target design prevents isolating per-gateway scheduling overhead and means Envoy Gateway's data-plane pods may not have been scheduled or captured.",
      "perTarget": {
        "app": "Single GKE cluster on e2-standard-4 (4 vCPU, 16 GB RAM) with 1 node, hosting all three gateways plus observability stack (Alloy, kube-state-metrics, operator) and a Tailscale VPN hub. Total experiment cost was $0.0165 USD for 0.617 hours. The node was massively under-utilized: 23.3 cumulative core-seconds of CPU over 2,221 seconds (0.010 avg cores, 0.26% of capacity) and 218 MiB memory working set (1.3% of 16 GB). The co-located topology is suitable for idle comparison but would introduce interference under load. Notably, only 7 pods were captured in metrics — the absence of envoy-default-* pods suggests Envoy Gateway's data-plane proxies either were not deployed with active GatewayClass/Gateway resources or were excluded from collection."
      },
      "comparisonToBaseline": "Comparing the three gateways at idle: Traefik was the lightest at 2.07 core-seconds CPU and 27.6 MiB memory, followed by NGINX Ingress at 2.40 core-seconds and 29.0 MiB, and Envoy Gateway's control plane at 3.74 core-seconds and 34.0 MiB. Envoy Gateway consumed 80% more CPU and 23% more memory than Traefik — and this only reflects its control-plane pod. The observability stack (Alloy at 7.64 core-seconds / 40.8 MiB, kube-state-metrics at 2.62 / 36.9 MiB, operator at 3.29 / 25.6 MiB) collectively exceeded any individual gateway's footprint, consuming 58% of total CPU and 47% of total memory. This means infrastructure overhead dominates gateway overhead in idle scenarios."
    },
    "performanceAnalysis": {
      "overview": "All three gateways demonstrated minimal idle resource consumption, collectively using less than 0.004 average cores and under 92 MiB of memory. The differences between them are small in absolute terms (sub-millicore CPU, single-digit MiB memory) but directionally consistent with architectural expectations. No load was applied, so proxy throughput, latency, and connection-handling performance remain unmeasured.",
      "findings": [
        "1. Traefik was the most resource-efficient gateway, consuming 2.07 core-seconds of CPU (0.93 millicores avg) and 27.6 MiB memory — 14% less CPU and 5% less memory than NGINX Ingress. This contradicts the hypothesis that NGINX's single-process model would be most efficient, suggesting Traefik's single Go binary architecture is at least equally lean.",
        "2. Envoy Gateway's control-plane pod consumed 3.74 core-seconds (1.68 millicores avg) and 34.0 MiB memory — 80% more CPU and 23% more memory than Traefik. Critically, the envoy-default-* data-plane proxy pods were not captured in metrics, meaning Envoy Gateway's true total footprint is materially undercounted. In production, the data-plane pods typically consume more resources than the control plane.",
        "3. NGINX Ingress consumed 2.40 core-seconds (1.08 millicores avg) and 29.0 MiB memory, placing it between Traefik and Envoy Gateway on both dimensions. Its single-process NGINX + Lua architecture is efficient but did not achieve the lowest footprint as hypothesized.",
        "4. The observability and platform stack consumed more resources than the gateways: Alloy alone used 7.64 core-seconds (3.44 millicores avg) and 40.8 MiB — more than any individual gateway by 2x on CPU. Combined with kube-state-metrics (2.62 core-sec, 36.9 MiB) and the operator (3.29 core-sec, 25.6 MiB), platform pods accounted for 58% of total CPU and 47% of total memory.",
        "5. Total cluster utilization was negligible: 23.3 cumulative core-seconds over 2,221 seconds translates to 0.010 average cores on a 4-core node (0.26% CPU utilization) and 218 MiB out of 16 GB RAM (1.3% memory utilization). The e2-standard-4 node is at least 4x over-provisioned for this workload.",
        "6. No load-generation phase was executed, so the experiment cannot differentiate proxy performance characteristics (throughput, latency percentiles, connection handling, TLS termination overhead) between the three gateways. Idle footprint alone is insufficient for production gateway selection."
      ],
      "bottlenecks": [
        "Envoy Gateway data-plane pods (envoy-default-*) were not captured in metrics, making it impossible to assess the true resource cost of Envoy Gateway's two-process architecture. This is the most significant gap in the experiment data.",
        "No traffic load was applied, so proxy-layer performance (throughput, p99 latency, connection scale) could not be measured. Idle CPU and memory reveal control-plane overhead but not data-path efficiency.",
        "Single-point-in-time cumulative CPU counters prevent distinguishing startup burst from steady-state consumption. Time-series collection with per-second rates would enable phase-specific analysis.",
        "Co-location of all gateways and observability on a single node means any load test would introduce cross-gateway interference, requiring dedicated node pools for isolated benchmarking."
      ]
    },
    "metricInsights": {
      "cpu_by_pod": "Envoy Gateway's control-plane pod led CPU consumption at 3.74 core-seconds (1.68 millicores avg), followed by the operator at 3.29 and kube-state-metrics at 2.62. Among gateways, NGINX Ingress used 2.40 core-seconds (1.08 millicores avg) and Traefik was lightest at 2.07 (0.93 millicores avg) — but Alloy dominated at 7.64 core-seconds (3.44 millicores avg), consuming more than any two gateway pods combined.",
      "cpu_total": "Total cumulative CPU across all 7 pods was 23.27 core-seconds over 2,221 seconds, yielding an average cluster utilization of 0.010 cores — just 0.26% of the e2-standard-4 node's 4-core capacity. The three gateway pods collectively accounted for only 8.21 core-seconds (35% of total), with observability and platform pods consuming the remaining 65%.",
      "memory_by_pod": "Memory working set ranged from 25.8 MiB (Tailscale hub) to 42.8 MiB (Alloy). Among gateways: Traefik at 27.6 MiB, NGINX Ingress at 29.0 MiB, and Envoy Gateway control plane at 34.0 MiB. Envoy Gateway's data-plane proxy pods are absent from this snapshot, so its true memory footprint is higher than the 34.0 MiB shown.",
      "memory_total": "Total memory working set across all pods was 218.5 MiB — just 1.3% of the node's 16 GB capacity. Gateway pods accounted for 90.6 MiB (41% of the total), while observability and platform pods consumed 127.9 MiB (59%). An e2-medium (4 GB) would comfortably host this workload at one-quarter the cost."
    },
    "architectureDiagram": "flowchart TD\n  subgraph hub[\"Hub Cluster\"]\n    operator[\"Operator Pod<br/>3.29 core-sec / 25.6 MiB\"]\n    tsHub[\"Tailscale Hub<br/>ts-vm-hub / 25.8 MiB\"]\n  end\n  subgraph app[\"App Cluster — e2-standard-4 (1 node)\"]\n    subgraph gateways[\"Gateway Controllers\"]\n      nginx[\"NGINX Ingress<br/>2.40 core-sec / 29.0 MiB\"]\n      traefik[\"Traefik<br/>2.07 core-sec / 27.6 MiB\"]\n      envoyCtrl[\"Envoy Gateway Controller<br/>3.74 core-sec / 34.0 MiB\"]\n      envoyDP[\"Envoy Data Plane<br/>(envoy-default-* not captured)\"]\n    end\n    subgraph observability[\"Observability Stack\"]\n      alloy[\"Alloy Agent<br/>7.64 core-sec / 40.8 MiB\"]\n      ksm[\"kube-state-metrics<br/>2.62 core-sec / 36.9 MiB\"]\n    end\n  end\n  operator -->|manages| app\n  tsHub -->|VPN tunnel| app\n  envoyCtrl -->|programs| envoyDP\n  alloy -->|scrapes cadvisor| nginx\n  alloy -->|scrapes cadvisor| traefik\n  alloy -->|scrapes cadvisor| envoyCtrl\n  ksm -->|watches| gateways",
    "architectureDiagramFormat": "mermaid",
    "finopsAnalysis": {
      "overview": "This 37-minute gateway comparison experiment ran on a single e2-standard-4 GKE node (4 vCPU, 16 GB RAM) and cost $0.0165 USD. The node was massively underutilized: total CPU averaged 0.010 cores (0.26% of 4 cores) and total memory working set was 218 MiB (1.3% of 16 GB). All three gateway controllers plus the observability stack fit comfortably on a single VM, meaning the minimum billable unit — one full e2-standard-4 instance — dominated cost regardless of workload.",
      "costDrivers": [
        "GKE node compute is the sole cost driver at $0.0165 for 0.617 hours of e2-standard-4 ($0.134/hr on-demand). The three gateway pods collectively used only 8.2 core-seconds of CPU and 91.0 MiB of memory — a fraction of the node's capacity. The cost floor is set by the VM, not the workload.",
        "Observability and platform pods (Alloy: 7.6 core-sec CPU / 42.8 MiB, kube-state-metrics: 2.6 core-sec / 36.9 MiB, operator: 3.3 core-sec / 25.6 MiB, Tailscale hub: 1.5 core-sec / 24.6 MiB) consumed 58% of total CPU and 47% of total memory — more than all three gateways combined. The monitoring tax exceeds the workload being monitored."
      ],
      "projection": "Production 24/7 operation requires HA (3 nodes across zones) and dedicated infrastructure per gateway. Math for a single gateway cluster: 3 × e2-standard-4 nodes × $0.134/hr × 730 hrs/month = $293.46/month. Running all three gateways in separate HA clusters: $293.46 × 3 = $880.38/month. Envoy Gateway's two-process architecture (controller + separate envoy-default-* data-plane pods, which were not captured in this experiment) requires larger nodes — e2-standard-8 at $0.268/hr — pushing its cluster to 3 × $0.268 × 730 = $586.92/month alone, bringing the three-gateway total to $880.38 + $293.46 (Envoy upgrade delta) = ~$1,174/month. With 1-year committed-use discounts (37% off): $554–$740/month. Additional production costs: 3 GCP load balancer forwarding rules at $18.26/month each ($54.78), persistent disks (~$20–40/month), and egress charges — adding $75–150/month per cluster. Realistic all-in monthly estimate for three production gateway clusters: $700–$1,100/month on-demand, $475–$750/month with CUDs. Consolidating all three onto a single 3-node e2-standard-8 cluster: 3 × $0.268 × 730 = $586.92/month + LB/disk/egress ≈ $650–$750/month.",
      "optimizations": [
        "Right-size the experiment node to e2-medium (2 vCPU, 4 GB) at $0.034/hr — sufficient for idle benchmarking and reduces per-run cost by 75% from $0.017 to ~$0.004. At scale (e.g., 100 experiment runs/month), this saves ~$1.30/month.",
        "Use spot/preemptible VMs for benchmarking at ~$0.040/hr for e2-standard-4 (70% discount), reducing this experiment to ~$0.005. Acceptable for non-production benchmarks where interruption is tolerable.",
        "Reduce observability overhead during short benchmarks: Alloy consumed 33% of total CPU. Lower collection frequency or scrape interval for sub-hour experiments, or use a shared external monitoring stack to eliminate per-experiment observability pods entirely.",
        "For production gateway selection, consolidate to a single gateway rather than running three. A single-gateway 3-node HA cluster costs $293–$587/month vs. $880–$1,174/month for three separate clusters — a 67% reduction by making a selection decision."
      ]
    },
    "secopsAnalysis": {
      "overview": "Three gateway controllers (NGINX Ingress, Traefik, Envoy Gateway) plus observability agents (Alloy, kube-state-metrics), a cluster operator, and a Tailscale VPN hub run on a single GKE node with no observable network segmentation, resource constraints, or hardened pod security posture. While the short-lived, single-node experiment topology limits blast radius, the deployed configuration reflects several security gaps that would be critical in production.",
      "findings": [
        "RBAC over-provisioning across three concurrent controllers: NGINX Ingress, Traefik, and Envoy Gateway each require ClusterRole bindings to watch Ingress, Gateway, HTTPRoute, and related resources across all namespaces. Running all three simultaneously creates three separate service accounts with broad cluster-wide read access to routing configuration. A compromised controller pod could enumerate all routing rules, backend service addresses, and TLS certificate references cluster-wide. In production, each controller's ClusterRole should be audited to restrict API groups (e.g., Envoy Gateway does not need networking.k8s.io/ingresses) and verbs to the minimum required.",
        "No NetworkPolicy enforcement observed: All seven pods (three gateways, Alloy, kube-state-metrics, operator, Tailscale hub) share the same network plane with no ingress/egress restrictions. This permits unrestricted lateral movement — a compromised Alloy telemetry pod could reach the Tailscale VPN hub, the Kubernetes API server, or any gateway's admin interface. Production deployments must enforce deny-all default NetworkPolicies per namespace, with explicit allow rules for each pod's required communication paths (e.g., gateway → API server:443, Alloy → kubelet:10250).",
        "Tailscale VPN hub (ts-vm-hub-xmccv-0) provides network-level remote access to the cluster and represents a high-value target. If its authentication keys are compromised, an attacker gains direct network connectivity to the cluster's pod network. This pod should run with a restrictive SecurityContext (readOnlyRootFilesystem: true, runAsNonRoot: true, drop ALL capabilities, add only NET_ADMIN if required), its auth keys should be short-lived and rotated, and it should be isolated in a dedicated namespace with strict NetworkPolicy.",
        "No resource limits or requests are evident in the deployment. Without limits, any pod (gateway or otherwise) can consume unbounded CPU and memory, enabling resource exhaustion attacks. A malicious request pattern against an unlimited NGINX Ingress pod could starve Traefik and Envoy Gateway of resources on this shared node. All pods should have CPU/memory requests and limits set, with requests sized to observed usage (e.g., 10m CPU / 64Mi memory for gateway idle) and limits set to prevent runaway consumption (e.g., 500m CPU / 256Mi memory).",
        "NGINX Ingress runs an embedded Lua interpreter (OpenResty/lua-nginx-module) for dynamic configuration updates, which expands the attack surface beyond static-config proxies. Historical CVEs (e.g., CVE-2023-5044 for annotation injection into Lua context) demonstrate this risk. All three controller images should be pinned to specific digests (not mutable tags), scanned for known CVEs, and verified that no critical or high-severity vulnerabilities are present in the deployed versions."
      ],
      "supplyChain": "Image provenance varies significantly across the three gateways and cannot be verified from experiment data alone. NGINX Ingress Controller images (registry.k8s.io/ingress-nginx/controller) have cosign signatures available from the Kubernetes project, but SBOM attestations are partial and not consistently published across all releases. Traefik images (docker.io/library/traefik) are published on Docker Hub without cosign signatures or SBOM attestations in their standard distribution channel as of early 2025 — this is the weakest supply chain posture of the three. Envoy Gateway images (docker.io/envoyproxy/gateway and envoyproxy/envoy) have begun adopting cosign-signed images with SLSA provenance attestations, though coverage varies by release. For production adoption: (1) all images should be mirrored to a private registry (e.g., Artifact Registry) with vulnerability scanning enabled; (2) an admission controller (Kyverno or OPA Gatekeeper) should enforce signature verification policies, rejecting unsigned images; (3) SBOM attestations should be required and ingested into a dependency tracking system — this is particularly important for NGINX (C + Lua native dependencies) and Envoy (C++ with BoringSSL) where transitive native-code vulnerabilities are not visible through container layer scanning alone; (4) Traefik's lack of cosign signatures should be flagged as a supply chain risk and raised with the Traefik project or mitigated by building from source with internal signing."
    },
    "capabilitiesMatrix": {
      "technologies": [
        "NGINX Ingress",
        "Traefik",
        "Envoy Gateway"
      ],
      "categories": [
        {
          "name": "Resource Efficiency",
          "capabilities": [
            {
              "name": "Avg CPU utilization (idle)",
              "values": {
                "NGINX Ingress": "~0.001 cores (2.4 core-sec / 2221s)",
                "Traefik": "~0.0009 cores (2.1 core-sec / 2221s) — lowest",
                "Envoy Gateway": "~0.0017 cores (3.7 core-sec / 2221s) — control plane only; data-plane pods not captured"
              }
            },
            {
              "name": "Memory working set (idle)",
              "values": {
                "NGINX Ingress": "~29 MiB",
                "Traefik": "~27.6 MiB — lowest",
                "Envoy Gateway": "~34 MiB — control plane only; true footprint higher with envoy-default-* pods"
              }
            },
            {
              "name": "Architectural overhead",
              "values": {
                "NGINX Ingress": "Single-process (NGINX + Lua controller in one pod)",
                "Traefik": "Single Go binary (control + data plane combined)",
                "Envoy Gateway": "Two-process split (Go controller pod + separate Envoy proxy pods); higher operational surface area"
              }
            }
          ]
        },
        {
          "name": "Gateway API Conformance",
          "capabilities": [
            {
              "name": "Native Gateway API support",
              "values": {
                "NGINX Ingress": "Translation layer add-on; not native",
                "Traefik": "Experimental provider; partial native support",
                "Envoy Gateway": "Reference implementation; fully native"
              }
            },
            {
              "name": "Conformance tier coverage",
              "values": {
                "NGINX Ingress": "Core only (via translation shim); limited Extended",
                "Traefik": "Core + some Extended; Experimental behind feature gates",
                "Envoy Gateway": "Core + Extended + broadest Experimental coverage"
              }
            }
          ]
        },
        {
          "name": "Configuration Model",
          "capabilities": [
            {
              "name": "Primary API surface",
              "values": {
                "NGINX Ingress": "Ingress resources + annotations; Gateway API via separate CRDs",
                "Traefik": "Three overlapping models: Ingress, IngressRoute CRDs, Gateway API",
                "Envoy Gateway": "Gateway API exclusively (HTTPRoute, GRPCRoute, etc.)"
              }
            },
            {
              "name": "Simple routing complexity",
              "values": {
                "NGINX Ingress": "Low — familiar annotation model",
                "Traefik": "Low to moderate — multiple overlapping APIs add cognitive load",
                "Envoy Gateway": "Moderate — more verbose but more expressive and structured"
              }
            },
            {
              "name": "Advanced configuration ergonomics",
              "values": {
                "NGINX Ingress": "Annotation sprawl; raw NGINX snippets needed for non-standard features",
                "Traefik": "Clean middleware chains via IngressRoute CRDs",
                "Envoy Gateway": "Structured CRDs (BackendTrafficPolicy, SecurityPolicy, EnvoyPatchPolicy)"
              }
            }
          ]
        },
        {
          "name": "Extensibility & Protocol Support",
          "capabilities": [
            {
              "name": "Filter / middleware architecture",
              "values": {
                "NGINX Ingress": "Limited — Lua plugins and NGINX snippets; no formal filter chain",
                "Traefik": "Built-in middleware chain (rate-limit, circuit-breaker, headers, auth forwarding)",
                "Envoy Gateway": "Full Envoy filter chain (Wasm, ext_proc, ext_authz, Lua); richest extensibility"
              }
            },
            {
              "name": "Protocol support beyond HTTP",
              "values": {
                "NGINX Ingress": "TCP/UDP via ConfigMap; gRPC supported",
                "Traefik": "TCP, UDP, gRPC natively via IngressRoute",
                "Envoy Gateway": "TCP, UDP, gRPC, HTTP/3 via Gateway API route types"
              }
            }
          ]
        }
      ],
      "summary": "Traefik wins on resource efficiency and configuration ergonomics for straightforward routing, narrowly beating NGINX Ingress on both idle CPU (~0.0009 vs ~0.001 cores) and memory (~27.6 vs ~29 MiB) while offering a cleaner middleware model. Envoy Gateway is the definitive winner for Gateway API conformance and extensibility via Envoy's filter chain, but its two-process architecture imposes higher overhead — and the true cost is materially undercounted here because data-plane proxy pods were not captured. The key trade-off: operational simplicity and lower resource cost (Traefik/NGINX) versus future-proof Gateway API nativeness and deep extensibility (Envoy Gateway), with the caveat that a load-tested experiment with complete Envoy metrics is required before making a production commitment."
    },
    "feedback": {
      "recommendations": [
        "Capture envoy-default-* data-plane proxy pods in metrics collection to measure Envoy Gateway's true total resource footprint — current data reflects only the control plane, making all resource comparisons structurally incomplete.",
        "Add a load-generation phase (hey or k6 at defined RPS targets) to compare request latency percentiles (p50/p95/p99), throughput ceiling, and error rates under realistic traffic; idle-only metrics cannot differentiate proxy performance.",
        "Run the official gateway-api/conformance test suite against all three implementations to produce concrete pass/fail data for Core, Extended, and Experimental features rather than relying on documentation claims.",
        "Test equivalent routing configurations across each gateway's native config model (NGINX annotations, Traefik IngressRoute, Envoy Gateway HTTPRoute) to compare operational complexity with concrete examples."
      ],
      "experimentDesign": [
        "Collect time-series data with distinct idle and loaded phases (15-30 minutes each) using rate-based CPU queries rather than cumulative counters from a single point-in-time snapshot, enabling per-phase resource trend analysis.",
        "Add application-level metrics (request latency p50/p95/p99, error rates, connection setup time, TLS handshake overhead) via a structured test client to measure actual proxy performance beyond infrastructure resource consumption.",
        "Run each gateway on a dedicated node pool or in separate experiment runs to eliminate co-tenant interference from observability pods (Alloy consumed 33% of total CPU) and system components, and right-size to e2-medium or spot instances to reduce per-run cost by 70-75%."
      ]
    },
    "body": {
      "blocks": [
        {
          "type": "text",
          "content": "This experiment deployed three Kubernetes gateway controllers — NGINX Ingress, Traefik, and Envoy Gateway — side-by-side on a single e2-standard-4 GKE node for 37 minutes. The goal: compare idle resource footprints, Gateway API maturity, configuration ergonomics, and extensibility."
        },
        {
          "type": "callout",
          "variant": "info",
          "title": "Idle-Only Benchmark",
          "content": "All measurements reflect idle control-plane resource usage with no traffic load applied. Envoy Gateway's data-plane proxy pods (envoy-default-*) were not captured in metrics, meaning its true total footprint is undercounted. Interpret resource comparisons accordingly."
        },
        {
          "type": "topic",
          "title": "Resource Efficiency",
          "blocks": [
            {
              "type": "text",
              "content": "All three gateways are remarkably lightweight at idle, collectively consuming less than 1.5% of the node's available resources. The differences are small in absolute terms but directionally consistent with architectural expectations."
            },
            {
              "type": "row",
              "blocks": [
                {
                  "type": "metric",
                  "key": "cpu_by_pod",
                  "size": "small",
                  "insight": "Envoy Gateway's control plane consumed 56% more CPU than Traefik — but all three averaged under 0.002 cores."
                },
                {
                  "type": "metric",
                  "key": "memory_by_pod",
                  "size": "small",
                  "insight": "Memory follows the same ranking: Envoy Gateway at ~34 MiB, NGINX at ~29 MiB, Traefik lightest at ~27.6 MiB."
                }
              ]
            },
            {
              "type": "comparison",
              "items": [
                {
                  "label": "Traefik",
                  "value": "2.1 core-sec / 27.6 MiB",
                  "description": "Lowest resource consumer — single Go binary combines control and data plane"
                },
                {
                  "label": "NGINX Ingress",
                  "value": "2.4 core-sec / 29.0 MiB",
                  "description": "Single-process model with embedded Lua controller keeps overhead minimal"
                },
                {
                  "label": "Envoy Gateway",
                  "value": "3.7 core-sec / 34.0 MiB",
                  "description": "Control plane only — separate data-plane proxy pods add uncaptured overhead"
                }
              ]
            },
            {
              "type": "callout",
              "variant": "warning",
              "title": "Envoy Gateway footprint is incomplete",
              "content": "Only the controller pod was captured. In production, envoy-default-* data-plane pods run separately and typically consume more resources than the control plane. The true resource envelope for Envoy Gateway is materially larger than shown."
            },
            {
              "type": "text",
              "content": "The observability stack (Alloy, kube-state-metrics, operator) consumed 58% of total CPU and 47% of total memory — more than all three gateways combined. In production, right-sizing monitoring overhead matters as much as gateway selection."
            },
            {
              "type": "metric",
              "key": "cpu_total",
              "size": "large",
              "insight": "23.3 core-seconds over 37 minutes — just 0.26% utilization of the 4-core node. The experiment node is at least 4x over-provisioned."
            }
          ]
        },
        {
          "type": "topic",
          "title": "Gateway API Conformance",
          "blocks": [
            {
              "type": "text",
              "content": "Gateway API support is the primary differentiator among these controllers. Their approaches range from native-first to bolted-on, directly impacting configuration ergonomics and future-proofing."
            },
            {
              "type": "capabilityRow",
              "capability": "Native Gateway API implementation",
              "values": {
                "NGINX Ingress": "Add-on translation layer; not native",
                "Traefik": "Experimental provider; partial native support",
                "Envoy Gateway": "Reference implementation; fully native"
              }
            },
            {
              "type": "capabilityRow",
              "capability": "Conformance level",
              "values": {
                "NGINX Ingress": "Core only (via translation); limited Extended support",
                "Traefik": "Core + some Extended; Experimental behind feature gates",
                "Envoy Gateway": "Core + Extended + broadest Experimental coverage"
              }
            },
            {
              "type": "capabilityRow",
              "capability": "Protocol support beyond HTTP",
              "values": {
                "NGINX Ingress": "TCP/UDP via ConfigMap; gRPC supported",
                "Traefik": "TCP, UDP, gRPC natively via IngressRoute",
                "Envoy Gateway": "TCP, UDP, gRPC, HTTP/3 via Gateway API route types"
              }
            },
            {
              "type": "callout",
              "variant": "finding",
              "title": "Hypothesis partially confirmed",
              "content": "Envoy Gateway is the clear leader in Gateway API conformance as the reference implementation. However, NGINX Ingress was not the most resource-efficient — Traefik narrowly beat it on both CPU (0.93 vs 1.08 millicores) and memory (27.6 vs 29.0 MiB), contradicting the hypothesis that NGINX's single-process model would be most efficient."
            }
          ]
        },
        {
          "type": "topic",
          "title": "Configuration Model & Extensibility",
          "blocks": [
            {
              "type": "text",
              "content": "Each gateway takes a fundamentally different approach to configuration, creating distinct trade-offs between familiarity, flexibility, and forward compatibility."
            },
            {
              "type": "table",
              "headers": [
                "Aspect",
                "NGINX Ingress",
                "Traefik",
                "Envoy Gateway"
              ],
              "rows": [
                [
                  "Primary API",
                  "Ingress + annotations",
                  "Ingress, IngressRoute CRDs, Gateway API",
                  "Gateway API exclusively"
                ],
                [
                  "Simple routing",
                  "Low — familiar annotations",
                  "Low to moderate — overlapping APIs",
                  "Moderate — verbose but expressive"
                ],
                [
                  "Advanced config",
                  "Annotation sprawl; NGINX snippets needed",
                  "Clean middleware chains via IngressRoute",
                  "Structured CRDs (BackendTrafficPolicy, SecurityPolicy)"
                ],
                [
                  "Filter architecture",
                  "Lua plugins; no formal chain",
                  "Built-in middleware chain",
                  "Full Envoy filter chain (Wasm, ext_proc, ext_authz)"
                ]
              ],
              "caption": "Configuration and extensibility comparison across all three gateways"
            },
            {
              "type": "text",
              "content": "Envoy Gateway's exclusive use of Gateway API avoids the configuration fragmentation that affects NGINX (annotation sprawl) and Traefik (three overlapping API surfaces). For teams already committed to Gateway API, it provides the cleanest path forward."
            }
          ]
        },
        {
          "type": "topic",
          "title": "Cost & Production Readiness",
          "blocks": [
            {
              "type": "text",
              "content": "This benchmark cost $0.017 USD on a single on-demand node. Extrapolating to production reveals meaningful cost differences driven by architecture rather than idle consumption."
            },
            {
              "type": "row",
              "blocks": [
                {
                  "type": "metric",
                  "key": "memory_total",
                  "size": "small",
                  "insight": "218 MiB total across all pods — just 1.3% of the node's 16 GB. An e2-medium would suffice at one-quarter the cost."
                },
                {
                  "type": "comparison",
                  "items": [
                    {
                      "label": "Experiment cost",
                      "value": "$0.017",
                      "description": "37 minutes on a single e2-standard-4 node"
                    },
                    {
                      "label": "Production (3 gateways)",
                      "value": "$880–$1,174/mo",
                      "description": "3-node HA clusters per gateway; Envoy Gateway requires larger nodes for data-plane pods"
                    },
                    {
                      "label": "With 1-year CUD",
                      "value": "$554–$740/mo",
                      "description": "37% committed-use discount applied"
                    }
                  ]
                }
              ]
            },
            {
              "type": "table",
              "headers": [
                "Security Concern",
                "Impact",
                "Mitigation"
              ],
              "rows": [
                [
                  "Cluster-wide RBAC for all three gateways",
                  "Broad read access to routing config across namespaces",
                  "Audit and scope ClusterRoles to minimum API groups and verbs"
                ],
                [
                  "No NetworkPolicy segmentation",
                  "Lateral movement between gateway, observability, and VPN pods",
                  "Enforce per-namespace deny-all defaults with explicit allow rules"
                ],
                [
                  "No resource limits set",
                  "Compromised pod can starve node of CPU/memory",
                  "Set requests and limits on all pods based on observed usage"
                ],
                [
                  "Mixed image provenance",
                  "Traefik lacks cosign signatures; NGINX partial; Envoy emerging",
                  "Pull from private registry with admission policy requiring signature verification"
                ]
              ],
              "caption": "Key security findings and recommended mitigations"
            }
          ]
        },
        {
          "type": "topic",
          "title": "Recommendations",
          "blocks": [
            {
              "type": "recommendation",
              "priority": "p0",
              "title": "Capture Envoy Gateway data-plane metrics",
              "description": "Include envoy-default-* proxy pods in metrics collection. Current data only reflects the control plane, making all resource comparisons structurally incomplete.",
              "effort": "low"
            },
            {
              "type": "recommendation",
              "priority": "p0",
              "title": "Add load-generation phase",
              "description": "Introduce traffic using hey or k6 with defined RPS targets to compare latency percentiles (p50/p95/p99) and throughput. Idle-only metrics cannot differentiate proxy performance.",
              "effort": "medium"
            },
            {
              "type": "recommendation",
              "priority": "p1",
              "title": "Run Gateway API conformance test suite",
              "description": "Deploy the official gateway-api/conformance suite against each implementation to produce concrete pass/fail data for Core, Extended, and Experimental features.",
              "effort": "medium"
            },
            {
              "type": "recommendation",
              "priority": "p1",
              "title": "Right-size experiment infrastructure",
              "description": "Use e2-medium or spot instances for idle benchmarks — the current node is 99.7% idle on CPU. Reduces per-run cost from $0.017 to ~$0.004.",
              "effort": "low"
            },
            {
              "type": "recommendation",
              "priority": "p2",
              "title": "Isolate gateways on dedicated node pools",
              "description": "Run each gateway in separate experiment runs or on dedicated nodes to eliminate co-tenant interference from observability pods (Alloy consumed 33% of total CPU).",
              "effort": "medium"
            },
            {
              "type": "recommendation",
              "priority": "p2",
              "title": "Enforce security baselines",
              "description": "Add NetworkPolicies, resource limits, pod security standards, and scoped RBAC before production evaluation to validate each gateway operates under realistic constraints.",
              "effort": "high"
            }
          ]
        },
        {
          "type": "text",
          "content": "Traefik emerges as the best balance of resource efficiency and configuration ergonomics for straightforward routing — lightest on both CPU and memory with cleaner advanced configuration than NGINX's annotation model. Envoy Gateway is the right choice for teams investing in Gateway API long-term and needing deep extensibility through Envoy's filter chain, but its true resource cost remains unquantified. A load-tested follow-up with complete Envoy data-plane metrics is essential before making a production commitment."
        }
      ]
    },
    "summary": "The hypothesis is largely supported: Envoy Gateway demonstrates the richest Gateway API feature set as the reference implementation with the broadest Core, Extended, and Experimental conformance coverage, and its control-plane pod alone consumed 56% more CPU (3.74 core-seconds vs. 2.40 for NGINX, 2.07 for Traefik) and 23% more memory (34.0 MiB vs. 29.0 MiB for NGINX, 27.6 MiB for Traefik) than either competitor over the 37-minute experiment — with its separate data-plane proxy pods (envoy-default-*) not even captured in metrics, meaning true overhead is materially higher. However, the hypothesis that NGINX Ingress would be the most resource-efficient is only partially confirmed: Traefik narrowly beat NGINX on both CPU (0.93 vs. 1.08 millicores average) and memory (27.6 vs. 29.0 MiB), indicating that a single Go binary architecture can match or exceed NGINX's single-process efficiency. The experiment is limited to idle resource footprints with no traffic load applied and incomplete Envoy Gateway metrics, so performance under load and true two-process overhead remain unquantified. The most actionable finding is that Envoy Gateway's data-plane pods must be included in metrics collection before any resource comparison can be considered complete.",
    "generatedAt": "2026-02-12T21:05:27Z",
    "model": "claude-opus-4-6"
  }
}
