{"id":"illm-k8s-ai-lab-68h","title":"Stale ArgoCD apps block new lab deployments","description":"When clusters are deleted via 'kind delete cluster', the ArgoCD apps remain in hub cluster and claim shared resources (ClusterRoles, ClusterRoleBindings, Namespaces). This causes new lab deployments to fail with 'is part of applications X and Y' errors. \n\nStale apps found: loki-tutorial-target, slo-tutorial-target, observability-cost-tutorial-target\n\nWorkaround: Manually delete stale ArgoCD apps before running new labs.\n\nRoot cause: kind:down task doesn't clean up ArgoCD apps when deleting clusters.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T13:13:39.350247155-05:00","created_by":"illm","updated_at":"2026-01-10T13:24:33.757053858-05:00","closed_at":"2026-01-10T13:24:33.757053858-05:00","close_reason":"Closed","labels":["config","prometheus-tutorial","toil"]}
{"id":"illm-k8s-ai-lab-86u","title":"cloud-provider-kind needs restart after new cluster creation","description":"When a new Kind cluster is created, cloud-provider-kind container cannot connect to it due to TLS certificate issues. LoadBalancer services remain in 'pending' state.\n\nError: 'tls: failed to verify certificate: x509: certificate signed by unknown authority'\n\nWorkaround: Restart cloud-provider-kind container after cluster creation.\n\nRoot cause: cloud-provider-kind doesn't automatically pick up credentials for new clusters.\n\nPossible fixes:\n1. Restart cloud-provider-kind after cluster creation in kind:up task\n2. Configure cloud-provider-kind to auto-reload when new clusters appear","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T14:04:56.331007316-05:00","created_by":"illm","updated_at":"2026-01-10T14:05:33.809441658-05:00","closed_at":"2026-01-10T14:05:33.809441658-05:00","close_reason":"Closed","labels":["networking","timing","toil"]}
{"id":"illm-k8s-ai-lab-rle","title":"Duplicate cluster secrets cause ArgoCD sync failures","description":"Two different secret naming patterns are used:\n- kind:up creates 'argocd-cluster-{cluster}' (line ~504)\n- kind:conduct creates 'cluster-{cluster}' (line ~794)\n- kind:down only deletes 'cluster-{cluster}'\n\nThis leaves orphaned 'argocd-cluster-*' secrets that cause 'there are 2 clusters with the same name' errors.\n\nFix: Standardize on one naming pattern and clean up both in down task.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T13:41:50.937981592-05:00","created_by":"illm","updated_at":"2026-01-10T13:45:51.370671733-05:00","closed_at":"2026-01-10T13:45:51.370671733-05:00","close_reason":"Closed","labels":["config","toil"]}
{"id":"illm-k8s-ai-lab-x1z","title":"ArgoCD app stuck in terminating state after cluster deletion","description":"When tearing down experiments, we delete the ArgoCD app with --wait=false then immediately delete the Kind cluster. But the app has a resources-finalizer that requires ArgoCD to clean up resources on the target cluster. Since the cluster is already deleted, the finalizer can never complete and the app is stuck forever in Terminating state.\n\nObserved: deletionTimestamp set but app not deleted due to finalizer.\n\nImpact: Subsequent deploys see 'resource is currently being deleted' warning and may not work correctly.\n\nFix options:\n1. Wait for app deletion before cluster deletion (slow)\n2. Remove finalizer before deleting app when cluster is being destroyed\n3. Use cascade=orphan to skip resource cleanup","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T13:34:12.184556089-05:00","created_by":"illm","updated_at":"2026-01-10T13:45:51.154939305-05:00","closed_at":"2026-01-10T13:45:51.154939305-05:00","close_reason":"Closed","labels":["config","timing","toil"]}
