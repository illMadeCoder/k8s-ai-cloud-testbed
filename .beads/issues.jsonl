{"id":"illm-k8s-ai-lab-08q","title":"otel-demo services crash: OTel schema conflict","description":"Services fail with: Failed to initialize tracer: failed to create resource: conflicting Schema URL: https://opentelemetry.io/schemas/1.26.0 and https://opentelemetry.io/schemas/1.24.0. Need to align OTel SDK versions.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-12T20:09:43.504031341-05:00","created_by":"illm","updated_at":"2026-01-12T20:15:08.112598336-05:00","closed_at":"2026-01-12T20:15:08.112598336-05:00","close_reason":"Fixed by upgrading OTel SDK to v1.33.0","labels":["otel-tutorial","toil"]}
{"id":"illm-k8s-ai-lab-3o4","title":"logging-comparison log-generator uses local image","description":"log-generator deployment uses 'log-generator:latest' which is a local image. Needs to be pushed to ttl.sh registry for Talos deployment.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-12T21:01:40.886143803-05:00","created_by":"illm","updated_at":"2026-01-12T21:02:03.002954628-05:00","closed_at":"2026-01-12T21:02:03.002954628-05:00","close_reason":"Closed","labels":["logging-comparison","toil"]}
{"id":"illm-k8s-ai-lab-666","title":"Add local-path-provisioner to Talos bootstrap","description":"## Summary\nAdded local-path-provisioner to Talos platform bootstrap to support PVC-based workloads.\n\n## Changes\n- `platforms/talos/manifests/local-path-provisioner.yaml` - New manifest with:\n  - PodSecurity labels (privileged) on namespace\n  - Default StorageClass annotation\n- `platforms/talos/Taskfile.yaml`:\n  - Updated bootstrap task to install both kube-vip and local-path-provisioner\n  - Added local-path-storage to preserved namespaces\n\n## Context\nDiscovered during loki-tutorial deployment that Talos had no StorageClass, causing Loki PVC to stay Pending.\n\n## Commit\n`65ebb02` - feat: Add local-path-provisioner to Talos bootstrap\n","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-12T07:35:33.567206Z","updated_at":"2026-01-12T07:35:33.567206Z","closed_at":"2026-01-12T07:35:33.567206Z"}
{"id":"illm-k8s-ai-lab-68h","title":"Stale ArgoCD apps block new lab deployments","description":"When clusters are deleted via 'kind delete cluster', the ArgoCD apps remain in hub cluster and claim shared resources (ClusterRoles, ClusterRoleBindings, Namespaces). This causes new lab deployments to fail with 'is part of applications X and Y' errors. \n\nStale apps found: loki-tutorial-target, slo-tutorial-target, observability-cost-tutorial-target\n\nWorkaround: Manually delete stale ArgoCD apps before running new labs.\n\nRoot cause: kind:down task doesn't clean up ArgoCD apps when deleting clusters.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T13:13:39.350247155-05:00","created_by":"illm","updated_at":"2026-01-10T13:24:33.757053858-05:00","closed_at":"2026-01-10T13:24:33.757053858-05:00","close_reason":"Closed","labels":["config","prometheus-tutorial","toil"]}
{"id":"illm-k8s-ai-lab-7eb","title":"Multi-namespace experiments need all namespaces PSS labeled","description":"Experiments like logging-comparison create multiple namespaces (loki, elasticsearch, monitoring, logging-comparison). The talos:up task only labels the main destination namespace, but DaemonSets like promtail/fluent-bit in sub-namespaces are blocked by PSS.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-12T21:03:00.810780882-05:00","created_by":"illm","updated_at":"2026-01-12T21:05:09.280020901-05:00","closed_at":"2026-01-12T21:05:09.280020901-05:00","close_reason":"Closed","labels":["logging-comparison","toil"]}
{"id":"illm-k8s-ai-lab-86u","title":"cloud-provider-kind needs restart after new cluster creation","description":"When a new Kind cluster is created, cloud-provider-kind container cannot connect to it due to TLS certificate issues. LoadBalancer services remain in 'pending' state.\n\nError: 'tls: failed to verify certificate: x509: certificate signed by unknown authority'\n\nWorkaround: Restart cloud-provider-kind container after cluster creation.\n\nRoot cause: cloud-provider-kind doesn't automatically pick up credentials for new clusters.\n\nPossible fixes:\n1. Restart cloud-provider-kind after cluster creation in kind:up task\n2. Configure cloud-provider-kind to auto-reload when new clusters appear","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T14:04:56.331007316-05:00","created_by":"illm","updated_at":"2026-01-10T14:05:33.809441658-05:00","closed_at":"2026-01-10T14:05:33.809441658-05:00","close_reason":"Closed","labels":["networking","timing","toil"]}
{"id":"illm-k8s-ai-lab-8ax","title":"talos:up PSS labels applied after DaemonSet pods rejected","description":"Step 4 labels namespaces AFTER Step 3 waits for sync, but DaemonSet pods are created during sync. Need to restart DaemonSets after labeling or label namespaces earlier.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-12T21:12:21.093166496-05:00","created_by":"illm","updated_at":"2026-01-12T21:12:52.438533524-05:00","closed_at":"2026-01-12T21:12:52.438533524-05:00","close_reason":"Closed","labels":["toil"]}
{"id":"illm-k8s-ai-lab-999","title":"otel-demo images expire after 2h (ttl.sh)","description":"The otel-demo services use ttl.sh ephemeral images with 2h TTL. Images expire, causing ImagePullBackOff. Need to either: (1) use persistent registry like ghcr.io, or (2) build images as part of 'up' command.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-12T20:02:19.689543454-05:00","created_by":"illm","updated_at":"2026-01-12T20:26:35.171492802-05:00","closed_at":"2026-01-12T20:26:35.171492802-05:00","close_reason":"Fixed with 24h TTL and imagePullPolicy: Always","labels":["otel-tutorial","toil"]}
{"id":"illm-k8s-ai-lab-9s1","title":"loki-tutorial promtail blocked by PodSecurity baseline","description":"Two issues: (1) PodSecurity baseline blocks hostPath - needs namespace label, (2) Promtail can't find logs - Talos uses different log paths than standard Linux. Core loki infra works, promtail needs Talos-specific config.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-12T20:29:42.928600681-05:00","created_by":"illm","updated_at":"2026-01-12T20:36:20.525164441-05:00","closed_at":"2026-01-12T20:36:20.525164441-05:00","close_reason":"Superseded by general Talos PSS issue","labels":["loki-tutorial","toil"]}
{"id":"illm-k8s-ai-lab-d8v","title":"Kibana OOMKilled - needs more memory","description":"Kibana container is OOMKilled with 512Mi limit. Needs 1Gi for stable operation.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-12T21:04:53.501749078-05:00","created_by":"illm","updated_at":"2026-01-12T21:05:09.270943794-05:00","closed_at":"2026-01-12T21:05:09.270943794-05:00","close_reason":"Closed","labels":["logging-comparison","toil"]}
{"id":"illm-k8s-ai-lab-dgz","title":"otel-demo pods missing securityContext for restricted PSS","description":"Pods warn about PodSecurity restricted mode: need securityContext.allowPrivilegeEscalation=false, capabilities.drop=[ALL], runAsNonRoot=true, seccompProfile","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-12T20:26:42.277331295-05:00","created_by":"illm","updated_at":"2026-01-12T20:26:42.277331295-05:00","labels":["config","otel-tutorial"]}
{"id":"illm-k8s-ai-lab-n0e","title":"tracing-comparison uses non-existent ghcr.io images","description":"Same as otel-tutorial - otel-demo services use ghcr.io images that don't exist.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-12T21:31:20.370836536-05:00","created_by":"illm","updated_at":"2026-01-12T21:32:06.06718126-05:00","closed_at":"2026-01-12T21:32:06.06718126-05:00","close_reason":"Closed","labels":["toil","tracing-comparison"]}
{"id":"illm-k8s-ai-lab-nd0","title":"otel-tutorial missing demo app images","description":"## Issue\notel-tutorial deployment fails due to missing container images.\n\n## Failing Images\n- `ghcr.io/illmadecoder/otel-demo-user-service:latest` - 403 Forbidden\n- `ghcr.io/illmadecoder/otel-demo-order-service:latest` - 403 Forbidden  \n- `ghcr.io/illmadecoder/otel-demo-payment-service:latest` - 403 Forbidden\n\n## Working Components\n- Grafana: Running\n- Prometheus: Running\n- OTEL Collector: Running\n- Tempo: Running\n\n## Action Required\nBuild and push demo app images, or replace with existing public OTEL demo images.\n\n## File\n`experiments/scenarios/otel-tutorial/manifests/otel-demo-app.yaml`\n","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-12T07:52:09.999549Z","updated_at":"2026-01-12T20:26:35.325050174-05:00","closed_at":"2026-01-12T20:26:35.325050174-05:00","close_reason":"Superseded by illm-k8s-ai-lab-999 fix"}
{"id":"illm-k8s-ai-lab-pcj","title":"Talos enforces Pod Security Standards - DaemonSets blocked","description":"Talos enforces PSS baseline by default. DaemonSets like promtail, node-exporter that need hostPath/hostNetwork/hostPID are blocked. Fix: label namespaces with pod-security.kubernetes.io/enforce=privileged. Consider adding this to talos:up task or ArgoCD app.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-12T20:36:20.437720096-05:00","created_by":"illm","updated_at":"2026-01-12T20:37:33.480990498-05:00","closed_at":"2026-01-12T20:37:33.480990498-05:00","close_reason":"Fixed by auto-labeling namespace in talos:up task","labels":["config","toil"]}
{"id":"illm-k8s-ai-lab-rle","title":"Duplicate cluster secrets cause ArgoCD sync failures","description":"Two different secret naming patterns are used:\n- kind:up creates 'argocd-cluster-{cluster}' (line ~504)\n- kind:conduct creates 'cluster-{cluster}' (line ~794)\n- kind:down only deletes 'cluster-{cluster}'\n\nThis leaves orphaned 'argocd-cluster-*' secrets that cause 'there are 2 clusters with the same name' errors.\n\nFix: Standardize on one naming pattern and clean up both in down task.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T13:41:50.937981592-05:00","created_by":"illm","updated_at":"2026-01-10T13:45:51.370671733-05:00","closed_at":"2026-01-10T13:45:51.370671733-05:00","close_reason":"Closed","labels":["config","toil"]}
{"id":"illm-k8s-ai-lab-wod","title":"Talos prometheus-tutorial deployment validation - 2026-01-12","description":"## Deployment Test Results\n\nFull tear-down and redeploy of prometheus-tutorial on Talos cluster.\n\n### Timing Summary\n| Phase | Duration |\n|-------|----------|\n| Tear down | 0s |\n| Reset cluster | 21s |\n| Create ArgoCD app | 0s |\n| Trigger sync | 0s |\n| Wait for sync | 24s |\n| Wait for pods ready | 6s |\n| **Total deploy** | **30s** |\n| URL validation | 5s |\n\n### URL Validation Results\n| Service | URL | HTTP Code | Response Time |\n|---------|-----|-----------|---------------|\n| Grafana | 192.168.1.241:80 | 302 | 0.018s |\n| Prometheus | 192.168.1.242:9090 | 200 | 0.017s |\n| metrics-app | 192.168.1.240:80 | 200 | 0.017s |\n| station-monitor | 192.168.1.243:80 | 200 | 0.078s |\n\n### Issues Fixed During Session\n1. **RBAC permissions for kube-vip** - Cloud provider needed `configmaps` (create/update) and `events` (create/patch) permissions\n2. **ArgoCD ComparisonError** - Added `ignoreDifferences` for ReplicaSet/Deployment status fields\n\n### Commits\n- `92ce6ee` - fix: Add ignoreDifferences for ReplicaSet/Deployment status fields\n- `496c699` - fix: Add missing RBAC permissions for kube-vip cloud provider\n\n### Performance Notes\n- Sync phase (24s) is the bottleneck - waiting for ArgoCD to reconcile\n- All URL response times excellent (\u003c0.1s)\n- station-monitor slightly slower (0.078s vs ~0.017s for others)\n","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-12T07:11:21.367117Z","updated_at":"2026-01-12T07:11:21.367117Z","closed_at":"2026-01-12T07:11:21.367117Z"}
{"id":"illm-k8s-ai-lab-x1z","title":"ArgoCD app stuck in terminating state after cluster deletion","description":"When tearing down experiments, we delete the ArgoCD app with --wait=false then immediately delete the Kind cluster. But the app has a resources-finalizer that requires ArgoCD to clean up resources on the target cluster. Since the cluster is already deleted, the finalizer can never complete and the app is stuck forever in Terminating state.\n\nObserved: deletionTimestamp set but app not deleted due to finalizer.\n\nImpact: Subsequent deploys see 'resource is currently being deleted' warning and may not work correctly.\n\nFix options:\n1. Wait for app deletion before cluster deletion (slow)\n2. Remove finalizer before deleting app when cluster is being destroyed\n3. Use cascade=orphan to skip resource cleanup","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T13:34:12.184556089-05:00","created_by":"illm","updated_at":"2026-01-10T13:45:51.154939305-05:00","closed_at":"2026-01-10T13:45:51.154939305-05:00","close_reason":"Closed","labels":["config","timing","toil"]}
