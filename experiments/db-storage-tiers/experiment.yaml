apiVersion: experiments.illm.io/v1alpha1
kind: Experiment
metadata:
  generateName: db-st-
  namespace: experiments
spec:
  title: "GKE Storage Tier Showdown: All 5 Disk Types from HDD to Hyperdisk Extreme"
  description: "Comparison: fsync-per-write vs no-fsync across all five GKE persistent disk types (pd-standard, pd-balanced, pd-ssd, hyperdisk-balanced, hyperdisk-extreme) on n2-standard-80 — measures how disk tier interacts with durability guarantees under sustained 60-second maximum-rate write bursts"
  tags: ["comparison", "storage", "database", "baseline"]
  series: cloud-database-internals
  publish: true

  analyzerConfig:
    sections:
      - abstract
      - capabilitiesMatrix
      - targetAnalysis
      - performanceAnalysis
      - metricInsights
      - finopsAnalysis
      - body
      - feedback
      - architectureDiagram
      - glossary

  hypothesis:
    claim: "Hyperdisk Extreme delivers 5-20x lower fsync latency than pd-standard and 2-5x lower than pd-ssd. Hyperdisk Balanced slots between pd-ssd and Hyperdisk Extreme. No-fsync writes remain uniformly fast across all disk types since they only hit the page cache."
    questions:
      - "How does fsync write latency vary across all five GKE disk types?"
      - "Is no-fsync latency truly independent of underlying disk type?"
      - "What is the sustained write throughput ceiling for each disk type under fsync?"
      - "Do node-level disk IOPS correlate with application-level fsync latency?"
      - "How does the fsync cost multiplier change across disk tiers?"
      - "Where do the Hyperdisk tiers slot in relative to traditional pd-standard/balanced/ssd?"
    focus:
      - "fsync latency distribution across all 5 disk types"
      - "Hyperdisk vs traditional PD latency comparison"
      - "sustained throughput ceiling per disk type"
      - "disk IOPS correlation with application latency"
      - "page-cache independence from disk type"
      - "cost-performance tradeoff across 5 disk tiers"

  codeSnippets:
    fsync-store:
      name: "Write with Conditional Fsync"
      description: "Single-row write that calls file.sync_all() (fsync) when in Fsync mode, ensuring each write is durably persisted to disk at the cost of latency."
      language: rust
      path: components/apps/naive-db/src/src/store.rs
      startLine: 72
      endLine: 87
      usedBy: ["naive-db-fsync-hdd", "naive-db-fsync-balanced", "naive-db-fsync-ssd", "naive-db-fsync-hyperdisk-balanced", "naive-db-fsync-hyperdisk-extreme"]
    nosync-store:
      name: "SyncMode Configuration"
      description: "Controls whether writes call fsync — set via NAIVE_DB_SYNC_MODE environment variable. In NoSync mode, writes land in the page cache only, trading durability for throughput."
      language: rust
      path: components/apps/naive-db/src/src/store.rs
      startLine: 9
      endLine: 22
      usedBy: ["naive-db-nosync-hdd", "naive-db-nosync-balanced", "naive-db-nosync-ssd", "naive-db-nosync-hyperdisk-balanced", "naive-db-nosync-hyperdisk-extreme"]

  targets:
    - name: app
      cluster:
        type: gke
        machineType: n2-standard-80
        preemptible: true
      components:
        - app: naive-db-storage-bench
        - app: db-storage-bench-loadgen
        - app: kube-prometheus-stack
          params:
            prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues: "false"
        - app: metrics-agent
        - app: metrics-egress

  metrics:
    # --- HDD variant: fsync ---
    - name: hdd_fsync_write_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-fsync-hdd\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "HDD fsync: P99 write latency"
      group: hdd

    - name: hdd_fsync_throughput
      query: "sum(rate(naivedb_operations_total{op=\"write\", app=\"naive-db-fsync-hdd\", namespace=~\"$EXPERIMENT\"}[$DURATION]))"
      type: instant
      unit: ops/s
      description: "HDD fsync: sustained write ops/sec"
      group: hdd

    - name: hdd_fsync_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_fsync_duration_seconds_bucket{app=\"naive-db-fsync-hdd\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "HDD fsync: P99 fsync-only latency"
      group: hdd

    # --- HDD variant: nosync ---
    - name: hdd_nosync_write_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-nosync-hdd\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "HDD nosync: P99 write latency"
      group: hdd

    - name: hdd_nosync_throughput
      query: "sum(rate(naivedb_operations_total{op=\"write\", app=\"naive-db-nosync-hdd\", namespace=~\"$EXPERIMENT\"}[$DURATION]))"
      type: instant
      unit: ops/s
      description: "HDD nosync: sustained write ops/sec"
      group: hdd

    # --- Balanced variant: fsync ---
    - name: balanced_fsync_write_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-fsync-balanced\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "Balanced fsync: P99 write latency"
      group: balanced

    - name: balanced_fsync_throughput
      query: "sum(rate(naivedb_operations_total{op=\"write\", app=\"naive-db-fsync-balanced\", namespace=~\"$EXPERIMENT\"}[$DURATION]))"
      type: instant
      unit: ops/s
      description: "Balanced fsync: sustained write ops/sec"
      group: balanced

    - name: balanced_fsync_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_fsync_duration_seconds_bucket{app=\"naive-db-fsync-balanced\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "Balanced fsync: P99 fsync-only latency"
      group: balanced

    # --- Balanced variant: nosync ---
    - name: balanced_nosync_write_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-nosync-balanced\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "Balanced nosync: P99 write latency"
      group: balanced

    - name: balanced_nosync_throughput
      query: "sum(rate(naivedb_operations_total{op=\"write\", app=\"naive-db-nosync-balanced\", namespace=~\"$EXPERIMENT\"}[$DURATION]))"
      type: instant
      unit: ops/s
      description: "Balanced nosync: sustained write ops/sec"
      group: balanced

    # --- SSD variant: fsync ---
    - name: ssd_fsync_write_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-fsync-ssd\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "SSD fsync: P99 write latency"
      group: ssd

    - name: ssd_fsync_throughput
      query: "sum(rate(naivedb_operations_total{op=\"write\", app=\"naive-db-fsync-ssd\", namespace=~\"$EXPERIMENT\"}[$DURATION]))"
      type: instant
      unit: ops/s
      description: "SSD fsync: sustained write ops/sec"
      group: ssd

    - name: ssd_fsync_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_fsync_duration_seconds_bucket{app=\"naive-db-fsync-ssd\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "SSD fsync: P99 fsync-only latency"
      group: ssd

    # --- SSD variant: nosync ---
    - name: ssd_nosync_write_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-nosync-ssd\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "SSD nosync: P99 write latency"
      group: ssd

    - name: ssd_nosync_throughput
      query: "sum(rate(naivedb_operations_total{op=\"write\", app=\"naive-db-nosync-ssd\", namespace=~\"$EXPERIMENT\"}[$DURATION]))"
      type: instant
      unit: ops/s
      description: "SSD nosync: sustained write ops/sec"
      group: ssd

    # --- Hyperdisk Balanced variant: fsync ---
    - name: hdb_fsync_write_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-fsync-hyperdisk-balanced\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "Hyperdisk Balanced fsync: P99 write latency"
      group: hdb

    - name: hdb_fsync_throughput
      query: "sum(rate(naivedb_operations_total{op=\"write\", app=\"naive-db-fsync-hyperdisk-balanced\", namespace=~\"$EXPERIMENT\"}[$DURATION]))"
      type: instant
      unit: ops/s
      description: "Hyperdisk Balanced fsync: sustained write ops/sec"
      group: hdb

    - name: hdb_fsync_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_fsync_duration_seconds_bucket{app=\"naive-db-fsync-hyperdisk-balanced\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "Hyperdisk Balanced fsync: P99 fsync-only latency"
      group: hdb

    # --- Hyperdisk Balanced variant: nosync ---
    - name: hdb_nosync_write_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-nosync-hyperdisk-balanced\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "Hyperdisk Balanced nosync: P99 write latency"
      group: hdb

    - name: hdb_nosync_throughput
      query: "sum(rate(naivedb_operations_total{op=\"write\", app=\"naive-db-nosync-hyperdisk-balanced\", namespace=~\"$EXPERIMENT\"}[$DURATION]))"
      type: instant
      unit: ops/s
      description: "Hyperdisk Balanced nosync: sustained write ops/sec"
      group: hdb

    # --- Hyperdisk Extreme variant: fsync ---
    - name: hde_fsync_write_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-fsync-hyperdisk-extreme\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "Hyperdisk Extreme fsync: P99 write latency"
      group: hde

    - name: hde_fsync_throughput
      query: "sum(rate(naivedb_operations_total{op=\"write\", app=\"naive-db-fsync-hyperdisk-extreme\", namespace=~\"$EXPERIMENT\"}[$DURATION]))"
      type: instant
      unit: ops/s
      description: "Hyperdisk Extreme fsync: sustained write ops/sec"
      group: hde

    - name: hde_fsync_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_fsync_duration_seconds_bucket{app=\"naive-db-fsync-hyperdisk-extreme\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "Hyperdisk Extreme fsync: P99 fsync-only latency"
      group: hde

    # --- Hyperdisk Extreme variant: nosync ---
    - name: hde_nosync_write_p99
      query: "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{app=\"naive-db-nosync-hyperdisk-extreme\", namespace=~\"$EXPERIMENT\"}[$DURATION])) by (le))"
      type: instant
      unit: seconds
      description: "Hyperdisk Extreme nosync: P99 write latency"
      group: hde

    - name: hde_nosync_throughput
      query: "sum(rate(naivedb_operations_total{op=\"write\", app=\"naive-db-nosync-hyperdisk-extreme\", namespace=~\"$EXPERIMENT\"}[$DURATION]))"
      type: instant
      unit: ops/s
      description: "Hyperdisk Extreme nosync: sustained write ops/sec"
      group: hde

    # --- Time-series (range) across all variants ---
    - name: write_latency_over_time
      query: "histogram_quantile(0.99, sum(rate(naivedb_write_duration_seconds_bucket{namespace=~\"$EXPERIMENT\"}[1m])) by (le, app))"
      type: range
      unit: seconds
      description: "P99 write latency over time by variant (10 series)"
      group: timeseries

    - name: fsync_latency_over_time
      query: "histogram_quantile(0.99, sum(rate(naivedb_fsync_duration_seconds_bucket{namespace=~\"$EXPERIMENT\"}[1m])) by (le, app))"
      type: range
      unit: seconds
      description: "P99 fsync-only latency over time by variant"
      group: timeseries

    - name: write_throughput_over_time
      query: "sum(rate(naivedb_operations_total{op=\"write\", namespace=~\"$EXPERIMENT\"}[1m])) by (app)"
      type: range
      unit: ops/s
      description: "Write throughput over time by variant (10 series)"
      group: timeseries

    - name: read_throughput_over_time
      query: "sum(rate(naivedb_operations_total{op=\"read\", namespace=~\"$EXPERIMENT\"}[1m])) by (app)"
      type: range
      unit: ops/s
      description: "Read throughput over time by variant"
      group: timeseries

    # --- Disk I/O metrics (node_exporter) ---
    - name: disk_write_iops
      query: "sum(rate(node_disk_writes_completed_total{namespace=~\"$EXPERIMENT\", device=~\"sd.*\"}[1m]))"
      type: range
      unit: ops/s
      description: "Node-level disk write IOPS (all data disks)"
      group: disk_io

    - name: disk_io_utilization
      query: "rate(node_disk_io_time_seconds_total{namespace=~\"$EXPERIMENT\", device=~\"sd.*\"}[1m])"
      type: range
      unit: "%"
      description: "Disk I/O utilization (time spent doing I/O per second)"
      group: disk_io

    # --- Totals ---
    - name: hdd_fsync_total_rows
      query: "naivedb_rows_total{app=\"naive-db-fsync-hdd\", namespace=~\"$EXPERIMENT\"}"
      type: instant
      unit: rows
      description: "HDD fsync: total rows written"
      group: totals

    - name: hdd_nosync_total_rows
      query: "naivedb_rows_total{app=\"naive-db-nosync-hdd\", namespace=~\"$EXPERIMENT\"}"
      type: instant
      unit: rows
      description: "HDD nosync: total rows written"
      group: totals

    - name: balanced_fsync_total_rows
      query: "naivedb_rows_total{app=\"naive-db-fsync-balanced\", namespace=~\"$EXPERIMENT\"}"
      type: instant
      unit: rows
      description: "Balanced fsync: total rows written"
      group: totals

    - name: balanced_nosync_total_rows
      query: "naivedb_rows_total{app=\"naive-db-nosync-balanced\", namespace=~\"$EXPERIMENT\"}"
      type: instant
      unit: rows
      description: "Balanced nosync: total rows written"
      group: totals

    - name: ssd_fsync_total_rows
      query: "naivedb_rows_total{app=\"naive-db-fsync-ssd\", namespace=~\"$EXPERIMENT\"}"
      type: instant
      unit: rows
      description: "SSD fsync: total rows written"
      group: totals

    - name: ssd_nosync_total_rows
      query: "naivedb_rows_total{app=\"naive-db-nosync-ssd\", namespace=~\"$EXPERIMENT\"}"
      type: instant
      unit: rows
      description: "SSD nosync: total rows written"
      group: totals

    - name: hdb_fsync_total_rows
      query: "naivedb_rows_total{app=\"naive-db-fsync-hyperdisk-balanced\", namespace=~\"$EXPERIMENT\"}"
      type: instant
      unit: rows
      description: "Hyperdisk Balanced fsync: total rows written"
      group: totals

    - name: hdb_nosync_total_rows
      query: "naivedb_rows_total{app=\"naive-db-nosync-hyperdisk-balanced\", namespace=~\"$EXPERIMENT\"}"
      type: instant
      unit: rows
      description: "Hyperdisk Balanced nosync: total rows written"
      group: totals

    - name: hde_fsync_total_rows
      query: "naivedb_rows_total{app=\"naive-db-fsync-hyperdisk-extreme\", namespace=~\"$EXPERIMENT\"}"
      type: instant
      unit: rows
      description: "Hyperdisk Extreme fsync: total rows written"
      group: totals

    - name: hde_nosync_total_rows
      query: "naivedb_rows_total{app=\"naive-db-nosync-hyperdisk-extreme\", namespace=~\"$EXPERIMENT\"}"
      type: instant
      unit: rows
      description: "Hyperdisk Extreme nosync: total rows written"
      group: totals

    # --- Cluster resources ---
    - name: cluster_cpu
      query: "sum(rate(container_cpu_usage_seconds_total{namespace=~\"$EXPERIMENT\", container!=\"\"}[1m]))"
      type: range
      unit: cores
      description: "Total workload CPU usage"
      group: cluster

    - name: cluster_memory
      query: "sum(container_memory_working_set_bytes{namespace=~\"$EXPERIMENT\", container!=\"\"})"
      type: range
      unit: bytes
      description: "Total workload memory usage"
      group: cluster

  workflow:
    template: db-storage-tiers-validation
    completion:
      mode: workflow
