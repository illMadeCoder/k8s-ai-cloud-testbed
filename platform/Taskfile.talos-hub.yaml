version: '3'

# Talos Hub - Hub cluster running on Talos hardware
#
# Usage:
#   task talos-hub:status      # Show hub status
#   task talos-hub:reset       # Reset hub (delete all non-system resources)
#   task talos-hub:redeploy    # Reset and redeploy hub application
#   task talos-hub:teardown    # Wipe etcd + reboot Talos (full node reset)
#   task talos-hub:deploy      # Full idempotent bootstrap from bare Talos
#   task talos-hub:cycle       # teardown → wait → deploy

silent: true

vars:
  CONTEXT: talos-hub
  TALOS_IP: 192.168.1.178
  # Namespaces to preserve during reset
  PRESERVED_NS: "kube-system kube-public kube-node-lease default local-path-storage argocd"
  OPENBAO_KEYS_FILE: ~/.illmlab/openbao-keys.json
  SECRETS_DIR: .secrets
  ARGOCD_CHART_VERSION: "7.7.5"
  TALOS_CONTROLPLANE_CONFIG: ~/.talos/controlplane.yaml

tasks:
  status:
    desc: Show Talos hub status
    cmds:
      - |
        echo "=== Talos Hub Status ==="
        echo ""

        echo "=== Nodes ==="
        kubectl --context {{.CONTEXT}} get nodes -o wide

        echo ""
        echo "=== ArgoCD Applications ==="
        kubectl --context {{.CONTEXT}} get applications -n argocd -o custom-columns="NAME:.metadata.name,SYNC:.status.sync.status,HEALTH:.status.health.status" 2>/dev/null || echo "ArgoCD not running"

        echo ""
        echo "=== Namespaces ==="
        kubectl --context {{.CONTEXT}} get namespaces

  reset:
    desc: Reset Talos hub (delete all non-system resources, keep ArgoCD)
    cmds:
      - |
        echo "=============================================="
        echo "  RESETTING TALOS HUB"
        echo "=============================================="
        echo ""

        # Step 0: Clean up ALL webhooks that block namespace deletion
        echo "Step 0: Cleaning up admission webhooks..."
        for wh in $(kubectl --context {{.CONTEXT}} get validatingwebhookconfigurations -o name 2>/dev/null | grep -E "kyverno|cert-manager|external-secrets|istio|openbao"); do
          echo "  Deleting $wh"
          kubectl --context {{.CONTEXT}} delete "$wh" --ignore-not-found 2>/dev/null || true
        done
        for wh in $(kubectl --context {{.CONTEXT}} get mutatingwebhookconfigurations -o name 2>/dev/null | grep -E "kyverno|cert-manager|external-secrets|istio|openbao"); do
          echo "  Deleting $wh"
          kubectl --context {{.CONTEXT}} delete "$wh" --ignore-not-found 2>/dev/null || true
        done

        # Step 0b: Clean up Tailscale managed resources (they have stale state after reset)
        echo ""
        echo "Step 0b: Cleaning up Tailscale managed resources..."
        kubectl --context {{.CONTEXT}} delete sts -n tailscale -l tailscale.com/managed=true --ignore-not-found 2>/dev/null || true
        kubectl --context {{.CONTEXT}} delete sts -n tailscale --all --ignore-not-found 2>/dev/null || true
        kubectl --context {{.CONTEXT}} delete svc -n tailscale -l tailscale.com/managed=true --ignore-not-found 2>/dev/null || true
        kubectl --context {{.CONTEXT}} delete secret -n tailscale -l tailscale.com/managed=true --ignore-not-found 2>/dev/null || true
        # Also delete the operator's state secret to force clean reconciliation
        kubectl --context {{.CONTEXT}} delete secret operator -n tailscale --ignore-not-found 2>/dev/null || true

        # Step 1: Delete hub application (remove finalizer first)
        echo ""
        echo "Step 1: Deleting hub application..."
        kubectl --context {{.CONTEXT}} patch application hub -n argocd -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
        kubectl --context {{.CONTEXT}} delete application hub -n argocd --wait=false 2>/dev/null || true

        # Step 2: Delete all child apps except argocd (remove finalizers)
        echo ""
        echo "Step 2: Deleting child applications..."
        for app in $(kubectl --context {{.CONTEXT}} get applications -n argocd -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
          if [ "$app" != "argocd" ]; then
            echo "  Deleting $app"
            kubectl --context {{.CONTEXT}} patch application "$app" -n argocd -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl --context {{.CONTEXT}} delete application "$app" -n argocd --wait=false 2>/dev/null || true
          fi
        done

        # Step 3: Wait for apps to be deleted
        echo ""
        echo "Step 3: Waiting for apps to be deleted..."
        for i in $(seq 1 30); do
          COUNT=$(kubectl --context {{.CONTEXT}} get applications -n argocd --no-headers 2>/dev/null | wc -l)
          if [ "$COUNT" -le 1 ]; then
            echo "  Apps cleaned up (only argocd remains)"
            break
          fi
          echo "  Waiting... $COUNT apps remaining ($i/30)"
          sleep 2
        done

        # Step 4: Delete non-system namespaces
        echo ""
        echo "Step 4: Deleting non-system namespaces..."
        PRESERVED="{{.PRESERVED_NS}}"
        for ns in $(kubectl --context {{.CONTEXT}} get namespaces -o jsonpath='{.items[*].metadata.name}'); do
          SKIP=false
          for p in $PRESERVED; do
            if [ "$ns" = "$p" ]; then
              SKIP=true
              break
            fi
          done
          if [ "$SKIP" = "false" ]; then
            echo "  Deleting namespace: $ns"
            kubectl --context {{.CONTEXT}} delete namespace "$ns" --wait=false 2>/dev/null || true
          fi
        done

        # Step 5: Clean up any stuck resources with finalizers
        echo ""
        echo "Step 5: Cleaning up stuck resources..."
        for ns in $(kubectl --context {{.CONTEXT}} get namespaces --field-selector=status.phase=Terminating -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
          echo "  Checking namespace: $ns"
          # Clean up PVCs first (they block namespace deletion)
          for pvc in $(kubectl --context {{.CONTEXT}} get pvc -n "$ns" -o name 2>/dev/null); do
            echo "    Removing finalizers from $pvc"
            kubectl --context {{.CONTEXT}} patch "$pvc" -n "$ns" -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
          done
          # Clean up other resources
          for res in $(kubectl --context {{.CONTEXT}} get all,jobs,secrets,configmaps -n "$ns" -o name 2>/dev/null); do
            kubectl --context {{.CONTEXT}} patch "$res" -n "$ns" -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
          done
          # Force finalize the namespace if still stuck
          kubectl --context {{.CONTEXT}} get ns "$ns" -o json 2>/dev/null | jq '.spec.finalizers = []' | kubectl --context {{.CONTEXT}} replace --raw "/api/v1/namespaces/$ns/finalize" -f - 2>/dev/null || true
        done

        # Step 6: Wait for namespace cleanup
        echo ""
        echo "Step 6: Waiting for namespace cleanup..."
        for i in $(seq 1 30); do
          REMAINING=$(kubectl --context {{.CONTEXT}} get namespaces --field-selector=status.phase=Terminating -o name 2>/dev/null | wc -l)
          if [ "$REMAINING" -eq 0 ]; then
            echo "  All namespaces cleaned up!"
            break
          fi
          echo "  $REMAINING namespaces still terminating... ($i/30)"
          sleep 3
        done

        echo ""
        echo "=== Reset Complete ==="
        kubectl --context {{.CONTEXT}} get namespaces

  redeploy:
    desc: Reset and redeploy Talos hub
    cmds:
      - task: reset
      - |
        echo ""
        echo "=============================================="
        echo "  REDEPLOYING TALOS HUB"
        echo "=============================================="
        echo ""

        # Step 1: Apply hub application
        echo "Step 1: Applying hub application..."
        kubectl --context {{.CONTEXT}} apply -f platform/bootstrap/hub-application.yaml

        # Step 2: Wait for apps to be created
        echo ""
        echo "Step 2: Waiting for apps to be created..."
        for i in $(seq 1 60); do
          COUNT=$(kubectl --context {{.CONTEXT}} get applications -n argocd --no-headers 2>/dev/null | wc -l)
          if [ "$COUNT" -ge 15 ]; then
            echo "  $COUNT apps created"
            break
          fi
          echo "  Waiting... $COUNT apps ($i/60)"
          sleep 5
        done

        # Step 3: Initialize OpenBao if needed
        echo ""
        echo "Step 3: Checking OpenBao..."
        for i in $(seq 1 30); do
          if kubectl --context {{.CONTEXT}} get pod openbao-0 -n openbao &>/dev/null; then
            echo "  OpenBao pod exists"
            break
          fi
          echo "  Waiting for OpenBao pod... ($i/30)"
          sleep 5
        done

        # Wait for openbao container to be running (not sidecar)
        for i in $(seq 1 60); do
          PHASE=$(kubectl --context {{.CONTEXT}} get pod openbao-0 -n openbao -o jsonpath='{.status.phase}' 2>/dev/null)
          if [ "$PHASE" = "Running" ]; then
            echo "  OpenBao pod is running"
            break
          fi
          echo "  Waiting for OpenBao to start... ($i/60)"
          sleep 2
        done

        # Wait a moment for the bao process to start
        sleep 5

        # Check if initialized
        INIT_STATUS=$(kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- bao status -format=json 2>/dev/null | jq -r '.initialized' || echo "unknown")

        if [ "$INIT_STATUS" = "false" ]; then
          echo "  OpenBao needs initialization..."
          INIT_OUTPUT=$(kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- bao operator init -key-shares=1 -key-threshold=1 -format=json 2>&1)

          # Save keys
          echo "$INIT_OUTPUT" > {{.OPENBAO_KEYS_FILE}}
          chmod 600 {{.OPENBAO_KEYS_FILE}}
          echo "  Keys saved to {{.OPENBAO_KEYS_FILE}}"

          # Unseal
          UNSEAL_KEY=$(echo "$INIT_OUTPUT" | jq -r '.unseal_keys_b64[0]')
          kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- bao operator unseal "$UNSEAL_KEY"

          # Get root token
          ROOT_TOKEN=$(echo "$INIT_OUTPUT" | jq -r '.root_token')

          # Enable KV v2
          kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- sh -c "BAO_TOKEN=$ROOT_TOKEN bao secrets enable -path=secret kv-v2" || true

          # Create ESO token in external-secrets namespace (wait for namespace to exist)
          for i in $(seq 1 30); do
            if kubectl --context {{.CONTEXT}} get namespace external-secrets &>/dev/null; then
              kubectl --context {{.CONTEXT}} create secret generic openbao-token -n external-secrets --from-literal=token="$ROOT_TOKEN" --dry-run=client -o yaml | kubectl --context {{.CONTEXT}} apply -f -
              echo "  ESO token created"
              break
            fi
            echo "  Waiting for external-secrets namespace... ($i/30)"
            sleep 5
          done

          # Restart ESO to pick up new token
          kubectl --context {{.CONTEXT}} rollout restart deployment -n external-secrets 2>/dev/null || true

          echo "  OpenBao initialized and configured"
        elif [ "$INIT_STATUS" = "true" ]; then
          # Check if sealed
          SEALED=$(kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- bao status -format=json 2>/dev/null | jq -r '.sealed')
          if [ "$SEALED" = "true" ]; then
            if [ -f "{{.OPENBAO_KEYS_FILE}}" ]; then
              UNSEAL_KEY=$(jq -r '.unseal_keys_b64[0]' {{.OPENBAO_KEYS_FILE}})
              kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- bao operator unseal "$UNSEAL_KEY"
              echo "  OpenBao unsealed"
            else
              echo "  ERROR: OpenBao is sealed but no keys file found at {{.OPENBAO_KEYS_FILE}}"
            fi
          else
            echo "  OpenBao already initialized and unsealed"

            # Verify ESO token is valid
            ROOT_TOKEN=$(jq -r '.root_token' {{.OPENBAO_KEYS_FILE}} 2>/dev/null || echo "")
            if [ -n "$ROOT_TOKEN" ]; then
              TOKEN_VALID=$(kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- sh -c "BAO_TOKEN=$ROOT_TOKEN bao token lookup" 2>/dev/null && echo "true" || echo "false")
              if [ "$TOKEN_VALID" = "false" ]; then
                echo "  WARNING: Stored root token is invalid. OpenBao may need reinitialization."
              fi
            fi
          fi
        fi

        # Step 4: Wait for apps to sync
        echo ""
        echo "Step 4: Waiting for apps to sync..."
        for i in $(seq 1 120); do
          TOTAL=$(kubectl --context {{.CONTEXT}} get applications -n argocd --no-headers 2>/dev/null | wc -l)
          SYNCED=$(kubectl --context {{.CONTEXT}} get applications -n argocd -o jsonpath='{.items[?(@.status.sync.status=="Synced")].metadata.name}' 2>/dev/null | wc -w)
          if [ "$TOTAL" -gt 0 ] && [ "$SYNCED" -ge "$((TOTAL * 80 / 100))" ]; then
            echo "  $SYNCED/$TOTAL apps synced (>80%)"
            break
          fi
          echo "  $SYNCED/$TOTAL apps synced ($i/120)"
          sleep 5
        done

        echo ""
        echo "=============================================="
        echo "  REDEPLOY COMPLETE"
        echo "=============================================="
        echo ""
        echo "Run 'task talos-hub:status' to check status"

  teardown:
    desc: Wipe etcd (STATE partition) and reboot Talos node. Image cache and local-path data survive.
    prompt: "This will WIPE etcd and reboot the Talos node at {{.TALOS_IP}}. Continue?"
    cmds:
      - |
        echo "=============================================="
        echo "  TEARING DOWN TALOS HUB"
        echo "=============================================="
        echo ""

        # Step 1: Backup OpenBao keys to .secrets/ (safety net)
        echo "Step 1: Backing up OpenBao keys..."
        mkdir -p {{.SECRETS_DIR}}
        if [ -f {{.OPENBAO_KEYS_FILE}} ]; then
          cp {{.OPENBAO_KEYS_FILE}} "{{.SECRETS_DIR}}/openbao-keys.json"
          chmod 600 "{{.SECRETS_DIR}}/openbao-keys.json"
          echo "  Keys backed up to {{.SECRETS_DIR}}/openbao-keys.json"
        elif [ -f "{{.SECRETS_DIR}}/openbao-keys.json" ]; then
          echo "  Keys already in {{.SECRETS_DIR}}/openbao-keys.json"
        else
          echo "  No keys file found (skipping)"
        fi

        # Step 2: Reset Talos (wipe STATE only, keep EPHEMERAL)
        echo ""
        echo "Step 2: Resetting Talos node (wiping STATE partition)..."
        talosctl reset --nodes {{.TALOS_IP}} --system-labels-to-wipe STATE --reboot --graceful=false

        echo ""
        echo "=============================================="
        echo "  TEARDOWN INITIATED"
        echo "=============================================="
        echo ""
        echo "Node is rebooting. Wait for Talos to come back, then run:"
        echo "  task talos-hub:deploy"
        echo ""
        echo "Or use 'task talos-hub:cycle' to automate the full process."

  deploy:
    desc: Full idempotent bootstrap from fresh or partial Talos state
    cmds:
      - |
        echo "=============================================="
        echo "  DEPLOYING TALOS HUB"
        echo "=============================================="
        echo ""

        # Step 1: Apply machine config if node is in maintenance mode
        echo "Step 1: Checking Talos node state..."
        if talosctl --nodes {{.TALOS_IP}} version &>/dev/null; then
          echo "  Node is running (config already applied)"
        else
          echo "  Node may be in maintenance mode, applying machine config..."
          if [ -f {{.TALOS_CONTROLPLANE_CONFIG}} ]; then
            talosctl apply-config --nodes {{.TALOS_IP}} --file {{.TALOS_CONTROLPLANE_CONFIG}} --insecure
            echo "  Config applied, waiting for node to boot..."
            for i in $(seq 1 60); do
              if talosctl --nodes {{.TALOS_IP}} version &>/dev/null; then
                echo "  Node is ready"
                break
              fi
              if [ "$i" -eq 60 ]; then
                echo "  ERROR: Node not ready after 10 minutes"
                exit 1
              fi
              echo "  Waiting... ($i/60)"
              sleep 10
            done
          else
            echo "  ERROR: No machine config found at {{.TALOS_CONTROLPLANE_CONFIG}}"
            exit 1
          fi
        fi

        # Step 2: Bootstrap etcd
        echo ""
        echo "Step 2: Bootstrapping etcd..."
        ETCD_STATE=$(talosctl --nodes {{.TALOS_IP}} service etcd 2>/dev/null | grep STATE | awk '{print $NF}' || echo "unknown")
        if [ "$ETCD_STATE" = "Running" ]; then
          echo "  etcd already running (skipping bootstrap)"
        else
          echo "  Bootstrapping etcd..."
          talosctl --nodes {{.TALOS_IP}} bootstrap
          echo "  Bootstrap initiated"
        fi

        # Step 3: Wait for Kubernetes API + Node Ready
        echo ""
        echo "Step 3: Waiting for Kubernetes API..."
        for i in $(seq 1 60); do
          if kubectl --context {{.CONTEXT}} get nodes &>/dev/null; then
            echo "  Kubernetes API is available"
            break
          fi
          if [ "$i" -eq 60 ]; then
            echo "  ERROR: Kubernetes API not available after 5 minutes"
            exit 1
          fi
          echo "  Waiting for API... ($i/60)"
          sleep 5
        done

        # Clean up stale node objects from previous cluster incarnation
        STALE_NODES=$(kubectl --context {{.CONTEXT}} get nodes --field-selector spec.unschedulable=true -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}' 2>/dev/null)
        if [ -n "$STALE_NODES" ]; then
          for NODE in $STALE_NODES; do
            echo "  Deleting stale node: $NODE"
            kubectl --context {{.CONTEXT}} delete node "$NODE" 2>/dev/null || true
          done
        fi

        echo "  Waiting for node to be Ready..."
        for i in $(seq 1 60); do
          # Check if ANY node is Ready (not just items[0], which may be stale)
          READY_COUNT=$(kubectl --context {{.CONTEXT}} get nodes -o jsonpath='{range .items[*]}{.status.conditions[?(@.type=="Ready")].status}{"\n"}{end}' 2>/dev/null | grep -c "True" || echo "0")
          if [ "$READY_COUNT" -ge 1 ]; then
            echo "  Node is Ready"
            break
          fi
          if [ "$i" -eq 60 ]; then
            echo "  ERROR: Node not Ready after 5 minutes"
            exit 1
          fi
          echo "  Waiting for node Ready... ($i/60)"
          sleep 5
        done

        # Step 4: Install ArgoCD via Helm
        echo ""
        echo "Step 4: Installing ArgoCD via Helm..."
        # Clean up admission webhooks that block Helm operations
        # After teardown, webhook configs persist but pods aren't ready yet,
        # causing "failed calling webhook" errors with failurePolicy: Fail
        for wh in $(kubectl --context {{.CONTEXT}} get validatingwebhookconfigurations -o name 2>/dev/null | grep -E "kyverno|cert-manager|external-secrets|istio|openbao"); do
          echo "  Deleting stale webhook: $wh"
          kubectl --context {{.CONTEXT}} delete "$wh" --ignore-not-found 2>/dev/null || true
        done
        for wh in $(kubectl --context {{.CONTEXT}} get mutatingwebhookconfigurations -o name 2>/dev/null | grep -E "kyverno|cert-manager|external-secrets|istio|openbao"); do
          echo "  Deleting stale webhook: $wh"
          kubectl --context {{.CONTEXT}} delete "$wh" --ignore-not-found 2>/dev/null || true
        done
        helm repo add argo https://argoproj.github.io/argo-helm 2>/dev/null || true
        helm repo update argo 2>/dev/null || true
        # Clear stale Helm release if stuck in pending-install/pending-upgrade
        HELM_STATUS=$(helm --kube-context {{.CONTEXT}} status argocd -n argocd -o json 2>/dev/null | jq -r '.info.status' || echo "")
        if echo "$HELM_STATUS" | grep -q "^pending-"; then
          echo "  Clearing stale Helm release (status: $HELM_STATUS)..."
          kubectl --context {{.CONTEXT}} delete secret -n argocd -l owner=helm,name=argocd 2>/dev/null || true
        fi
        helm upgrade --install argocd argo/argo-cd \
          --namespace argocd --create-namespace \
          --version {{.ARGOCD_CHART_VERSION}} \
          --values platform/bootstrap/argocd-values-talos.yaml \
          --kube-context {{.CONTEXT}} \
          --wait --timeout 5m
        echo "  ArgoCD installed"

        # Step 5: Apply hub application
        echo ""
        echo "Step 5: Applying hub application..."
        kubectl --context {{.CONTEXT}} apply -f platform/bootstrap/hub-application.yaml
        echo "  Hub application applied"

        # Step 6: Wait for child apps (≥15 apps)
        echo ""
        echo "Step 6: Waiting for child apps to be created..."
        for i in $(seq 1 60); do
          COUNT=$(kubectl --context {{.CONTEXT}} get applications -n argocd --no-headers 2>/dev/null | wc -l)
          if [ "$COUNT" -ge 15 ]; then
            echo "  $COUNT apps created"
            break
          fi
          if [ "$i" -eq 60 ]; then
            echo "  WARNING: Only $COUNT apps after 5 minutes (expected ≥15)"
          fi
          echo "  Waiting... $COUNT apps ($i/60)"
          sleep 5
        done

        # Step 7: OpenBao init/unseal
        echo ""
        echo "Step 7: Checking OpenBao..."
        for i in $(seq 1 30); do
          if kubectl --context {{.CONTEXT}} get pod openbao-0 -n openbao &>/dev/null; then
            echo "  OpenBao pod exists"
            break
          fi
          echo "  Waiting for OpenBao pod... ($i/30)"
          sleep 5
        done

        # Wait for openbao container to be running
        for i in $(seq 1 60); do
          PHASE=$(kubectl --context {{.CONTEXT}} get pod openbao-0 -n openbao -o jsonpath='{.status.phase}' 2>/dev/null)
          if [ "$PHASE" = "Running" ]; then
            echo "  OpenBao pod is running"
            break
          fi
          echo "  Waiting for OpenBao to start... ($i/60)"
          sleep 2
        done

        # Wait for bao process to start
        sleep 5

        # Check if initialized
        INIT_STATUS=$(kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- bao status -format=json 2>/dev/null | jq -r '.initialized' || echo "unknown")

        if [ "$INIT_STATUS" = "false" ]; then
          echo "  OpenBao needs initialization..."
          INIT_OUTPUT=$(kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- bao operator init -key-shares=1 -key-threshold=1 -format=json 2>&1)

          # Save keys to both locations
          mkdir -p {{.SECRETS_DIR}}
          echo "$INIT_OUTPUT" > "{{.SECRETS_DIR}}/openbao-keys.json"
          chmod 600 "{{.SECRETS_DIR}}/openbao-keys.json"
          mkdir -p "$(dirname {{.OPENBAO_KEYS_FILE}})"
          echo "$INIT_OUTPUT" > {{.OPENBAO_KEYS_FILE}}
          chmod 600 {{.OPENBAO_KEYS_FILE}}
          echo "  Keys saved to {{.SECRETS_DIR}}/openbao-keys.json and {{.OPENBAO_KEYS_FILE}}"

          # Unseal
          UNSEAL_KEY=$(echo "$INIT_OUTPUT" | jq -r '.unseal_keys_b64[0]')
          kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- bao operator unseal "$UNSEAL_KEY"

          # Get root token
          ROOT_TOKEN=$(echo "$INIT_OUTPUT" | jq -r '.root_token')

          # Enable KV v2
          kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- sh -c "BAO_TOKEN=$ROOT_TOKEN bao secrets enable -path=secret kv-v2" || true

          echo "  OpenBao initialized and unsealed"

        elif [ "$INIT_STATUS" = "true" ]; then
          SEALED=$(kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- bao status -format=json 2>/dev/null | jq -r '.sealed')
          if [ "$SEALED" = "true" ]; then
            echo "  OpenBao is sealed, unsealing..."
            UNSEAL_KEY=""
            if [ -f "{{.SECRETS_DIR}}/openbao-keys.json" ]; then
              UNSEAL_KEY=$(jq -r '.unseal_keys_b64[0]' "{{.SECRETS_DIR}}/openbao-keys.json")
              echo "  Using keys from {{.SECRETS_DIR}}/openbao-keys.json"
            elif [ -f "{{.OPENBAO_KEYS_FILE}}" ]; then
              UNSEAL_KEY=$(jq -r '.unseal_keys_b64[0]' {{.OPENBAO_KEYS_FILE}})
              echo "  Using keys from {{.OPENBAO_KEYS_FILE}}"
            fi
            if [ -n "$UNSEAL_KEY" ]; then
              kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- bao operator unseal "$UNSEAL_KEY"
              echo "  OpenBao unsealed"
            else
              echo "  ERROR: OpenBao is sealed but no keys found in {{.SECRETS_DIR}}/ or {{.OPENBAO_KEYS_FILE}}"
              exit 1
            fi
          else
            echo "  OpenBao already initialized and unsealed"
          fi
        else
          echo "  WARNING: Could not determine OpenBao init status (got: $INIT_STATUS)"
        fi

        # Extract ROOT_TOKEN for subsequent steps
        ROOT_TOKEN=""
        if [ -f "{{.SECRETS_DIR}}/openbao-keys.json" ]; then
          ROOT_TOKEN=$(jq -r '.root_token' "{{.SECRETS_DIR}}/openbao-keys.json" 2>/dev/null || echo "")
        fi
        if [ -z "$ROOT_TOKEN" ] && [ -f "{{.OPENBAO_KEYS_FILE}}" ]; then
          ROOT_TOKEN=$(jq -r '.root_token' {{.OPENBAO_KEYS_FILE}} 2>/dev/null || echo "")
        fi

        # Step 8: Restore credentials from .secrets/
        echo ""
        echo "Step 8: Restoring credentials from {{.SECRETS_DIR}}/..."

        if [ -n "$ROOT_TOKEN" ]; then
          # GCP credentials (file-based approach for JSON with special chars)
          if [ -f "{{.SECRETS_DIR}}/gcp-credentials.json" ]; then
            echo "  Restoring GCP credentials..."
            kubectl --context {{.CONTEXT}} cp "{{.SECRETS_DIR}}/gcp-credentials.json" openbao/openbao-0:/tmp/gcp-creds.json -c openbao
            kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- \
              sh -c "BAO_TOKEN=$ROOT_TOKEN bao kv put secret/cloud/gcp credentials=@/tmp/gcp-creds.json"
            kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- rm /tmp/gcp-creds.json
            echo "  GCP credentials restored to secret/cloud/gcp"
          else
            echo "  No GCP credentials found (skipping)"
          fi

          # AWS credentials
          if [ -f "{{.SECRETS_DIR}}/aws-credentials.json" ]; then
            echo "  Restoring AWS credentials..."
            ACCESS_KEY_ID=$(jq -r '.accessKeyId' "{{.SECRETS_DIR}}/aws-credentials.json")
            SECRET_ACCESS_KEY=$(jq -r '.secretAccessKey' "{{.SECRETS_DIR}}/aws-credentials.json")
            kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- \
              sh -c "BAO_TOKEN=$ROOT_TOKEN bao kv put secret/cloud/aws accessKeyId=$ACCESS_KEY_ID secretAccessKey=$SECRET_ACCESS_KEY"
            echo "  AWS credentials restored to secret/cloud/aws"
          else
            echo "  No AWS credentials found (skipping)"
          fi

          # Azure credentials
          if [ -f "{{.SECRETS_DIR}}/azure-credentials.json" ]; then
            echo "  Restoring Azure credentials..."
            CLIENT_ID=$(jq -r '.clientId' "{{.SECRETS_DIR}}/azure-credentials.json")
            CLIENT_SECRET=$(jq -r '.clientSecret' "{{.SECRETS_DIR}}/azure-credentials.json")
            SUBSCRIPTION_ID=$(jq -r '.subscriptionId' "{{.SECRETS_DIR}}/azure-credentials.json")
            TENANT_ID=$(jq -r '.tenantId' "{{.SECRETS_DIR}}/azure-credentials.json")
            kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- \
              sh -c "BAO_TOKEN=$ROOT_TOKEN bao kv put secret/cloud/azure clientId=$CLIENT_ID clientSecret=$CLIENT_SECRET subscriptionId=$SUBSCRIPTION_ID tenantId=$TENANT_ID"
            echo "  Azure credentials restored to secret/cloud/azure"
          else
            echo "  No Azure credentials found (skipping)"
          fi

          # Tailscale OAuth credentials (ExternalSecret syncs secret/tailscale → operator-oauth secret)
          if [ -f "{{.SECRETS_DIR}}/tailscale.json" ]; then
            echo "  Restoring Tailscale OAuth credentials..."
            TS_CLIENT_ID=$(jq -r '.clientId' "{{.SECRETS_DIR}}/tailscale.json")
            TS_AUTH_KEY=$(jq -r '.authKey' "{{.SECRETS_DIR}}/tailscale.json")
            kubectl --context {{.CONTEXT}} exec -n openbao openbao-0 -c openbao -- \
              sh -c "BAO_TOKEN=$ROOT_TOKEN bao kv put secret/tailscale client_id=$TS_CLIENT_ID client_secret=$TS_AUTH_KEY"
            echo "  Tailscale credentials restored to secret/tailscale"
          else
            echo "  No Tailscale credentials found (skipping)"
          fi
        else
          echo "  WARNING: No root token available, skipping credential restore"
        fi

        # Step 9: Create ESO token
        echo ""
        echo "Step 9: Creating ESO token..."
        if [ -n "$ROOT_TOKEN" ]; then
          for i in $(seq 1 30); do
            if kubectl --context {{.CONTEXT}} get namespace external-secrets &>/dev/null; then
              kubectl --context {{.CONTEXT}} create secret generic openbao-token \
                -n external-secrets \
                --from-literal=token="$ROOT_TOKEN" \
                --dry-run=client -o yaml | kubectl --context {{.CONTEXT}} apply -f -
              echo "  ESO token created"
              # Restart ESO deployments to pick up new token
              kubectl --context {{.CONTEXT}} rollout restart deployment -n external-secrets 2>/dev/null || true
              echo "  ESO deployments restarted"
              break
            fi
            if [ "$i" -eq 30 ]; then
              echo "  WARNING: external-secrets namespace not found after 2.5 minutes"
            fi
            echo "  Waiting for external-secrets namespace... ($i/30)"
            sleep 5
          done
        else
          echo "  WARNING: No root token available, skipping ESO token creation"
        fi

        # Step 10: Wait for 80%+ apps synced
        echo ""
        echo "Step 10: Waiting for apps to sync (80%+ target)..."
        for i in $(seq 1 120); do
          TOTAL=$(kubectl --context {{.CONTEXT}} get applications -n argocd --no-headers 2>/dev/null | wc -l)
          SYNCED=$(kubectl --context {{.CONTEXT}} get applications -n argocd -o jsonpath='{.items[?(@.status.sync.status=="Synced")].metadata.name}' 2>/dev/null | wc -w)
          if [ "$TOTAL" -gt 0 ] && [ "$SYNCED" -ge "$((TOTAL * 80 / 100))" ]; then
            echo "  $SYNCED/$TOTAL apps synced (≥80%)"
            break
          fi
          if [ "$i" -eq 120 ]; then
            echo "  WARNING: Only $SYNCED/$TOTAL apps synced after 10 minutes"
          fi
          echo "  $SYNCED/$TOTAL apps synced ($i/120)"
          sleep 5
        done

        # Step 11: Status summary
        echo ""
        echo "=============================================="
        echo "  DEPLOY COMPLETE"
        echo "=============================================="
        echo ""
        echo "=== Nodes ==="
        kubectl --context {{.CONTEXT}} get nodes -o wide
        echo ""
        echo "=== ArgoCD Applications ==="
        kubectl --context {{.CONTEXT}} get applications -n argocd -o custom-columns="NAME:.metadata.name,SYNC:.status.sync.status,HEALTH:.status.health.status" 2>/dev/null || echo "ArgoCD not available"
        echo ""
        echo "=== ArgoCD Admin Password ==="
        ARGOCD_PASS=$(kubectl --context {{.CONTEXT}} get secret argocd-initial-admin-secret -n argocd -o jsonpath='{.data.password}' 2>/dev/null | base64 -d 2>/dev/null || echo "not available")
        echo "  admin / $ARGOCD_PASS"
        echo ""
        echo "Run 'task talos-hub:status' for full status"

  cycle:
    desc: Full teardown → wait for reboot → deploy cycle
    cmds:
      - task: teardown
      - |
        echo ""
        echo "=============================================="
        echo "  WAITING FOR TALOS NODE TO COME BACK"
        echo "=============================================="
        echo ""

        # Use --insecure: after STATE wipe the node boots into maintenance mode
        # with different TLS, so authenticated talosctl calls fail.
        # Note: talosctl version --insecure exits 1 in maintenance mode
        # ("API is not implemented"), so check output content, not exit code.
        for i in $(seq 1 60); do
          if talosctl --nodes {{.TALOS_IP}} version --insecure 2>&1 | grep -q "Tag:"; then
            echo "  Talos node is back online (maintenance mode)"
            break
          fi
          if [ "$i" -eq 60 ]; then
            echo "  ERROR: Talos node not reachable after 10 minutes"
            exit 1
          fi
          echo "  Waiting for Talos node... ($i/60)"
          sleep 10
        done

        # Extra settle time for services to stabilize
        echo "  Settling for 10 seconds..."
        sleep 10
      - task: deploy
